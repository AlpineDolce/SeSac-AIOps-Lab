# 🧠 CNN 실전 프로젝트: 이진 및 다중 이미지 분류 마스터

> 본 문서는 Convolutional Neural Network(CNN)를 활용한 두 가지 실전 이미지 분류 프로젝트(개/고양이 이진 분류, 꽃 다중 분류)를 상세히 다룹니다. 데이터 전처리부터 모델 설계, 데이터 증강 기법 적용, 그리고 학습 결과 분석에 이르는 전 과정을 통해 CNN의 핵심 원리와 실제 적용 능력을 보여줍니다.

---

## 목차

1.  [**프로젝트 개요**](#1-프로젝트-개요)
    *   [1.1 학습 목표](#11-학습-목표)
    *   [1.2 주요 기술 스택](#12-주요-기술-스택)
2.  [**프로젝트 1: 개와 고양이 이미지 이진 분류**](#2-프로젝트-1-개와-고양이-이미지-이진-분류)
    *   [2.1 데이터 준비 및 설정](#21-데이터-준비-및-설정)
    *   [2.2 데이터 증강을 포함한 CNN 모델 아키텍처](#22-데이터-증강을-포함한-cnn-모델-아키텍처)
    *   [2.3 모델 컴파일 및 학습](#23-모델-컴파일-및-학습)
    *   [2.4 학습 결과 및 분석](#24-학습-결과-및-분석)
3.  [**프로젝트 2: 꽃 이미지 다중 분류**](#3-프로젝트-2-꽃-이미지-다중-분류)
    *   [3.1 체계적인 데이터 전처리 및 분할](#31-체계적인-데이터-전처리-및-분할)
    *   [3.2 다중 분류를 위한 모델 설계](#32-다중-분류를-위한-모델-설계)
    *   [3.3 학습 결과 및 특징](#33-학습-결과-및-특징)
4.  [**두 프로젝트 아키텍처 비교 분석**](#4-두-프로젝트-아키텍처-비교-분석)
    *   [4.1 공통점: 재사용 가능한 CNN 구조](#41-공통점-재사용-가능한-cnn-구조)
    *   [4.2 차이점: 문제 유형에 따른 모델 변경](#42-차이점-문제-유형에-따른-모델-변경)
5.  [**핵심 기술: 데이터 증강(Data Augmentation)**](#5-핵심-기술-데이터-증강data-augmentation)
    *   [5.1 적용된 증강 기법과 그 효과](#51-적용된-증강-기법과-그-효과)
    *   [5.2 데이터 증강의 장점](#52-데이터-증강의-장점)
6.  [**종합 결론 및 향후 과제**](#6-종합-결론-및-향후-과제)
    *   [6.1 주요 학습 성과 요약](#61-주요-학습-성과-요약)
    *   [6.2 성능 개선을 위한 다음 단계](#62-성능-개선을-위한-다음-단계)
    *   [6.3 핵심 인사이트](#63-핵심-인사이트)

---

## 1. 프로젝트 개요

### 1.1 학습 목표

이번 학습에서는 **합성곱 신경망(CNN)**을 활용하여 두 가지 핵심적인 이미지 분류 프로젝트를 수행합니다. 이를 통해 다음의 역량을 강화하는 것을 목표로 합니다.

-   **CNN 기본 구조**의 이해 및 직접 구현 능력 배양
-   **이진 분류(Binary Classification)**와 **다중 클래스 분류(Multi-class Classification)** 문제 해결 능력 비교 및 습득
-   **데이터 증강(Data Augmentation)** 기법의 원리를 이해하고 실제 모델에 적용하여 과적합 제어
-   **TensorFlow/Keras** 프레임워크를 활용한 End-to-End 모델링 파이프라인 구축
-   모델의 성능을 체계적으로 분석하고 최적화하는 방법론 학습

### 1.2 주요 기술 스택

-   **프레임워크**: TensorFlow 2.19.0, Keras 3.10.0
-   **프로그래밍 언어**: Python 3.11.13
-   **핵심 라이브러리**: NumPy, Matplotlib, Pillow (PIL), OS

---

## 2. 프로젝트 1: 개와 고양이 이미지 이진 분류

### 2.1 데이터 준비 및 설정

-   **목표**: 주어진 이미지가 '개'인지 '고양이'인지 구분하는 이진 분류 모델 구축.
-   **데이터**: Kaggle의 "Dogs vs. Cats" 데이터셋 중 25,000장을 샘플링하여 총 4,000장 사용.
    -   훈련(Training) 데이터: 2,000장
    -   검증(Validation) 데이터: 1,000장
    -   테스트(Test) 데이터: 1,000장
-   **이미지 사양**: 180×180 픽셀 크기의 컬러(RGB) 이미지.
-   **배치 크기**: 16 (한 번에 16개의 이미지를 묶어 모델을 학습).

### 2.2 데이터 증강을 포함한 CNN 모델 아키텍처

제한된 데이터셋으로 인한 과적합을 방지하고 모델의 일반화 성능을 높이기 위해, Keras의 전처리 레이어를 활용하여 **실시간 데이터 증강(On-the-fly Data Augmentation)**을 모델의 일부로 통합했습니다.

```python
from tensorflow import keras
from tensorflow.keras import layers

def create_cat_dog_model(input_shape=(180, 180, 3)):
    """데이터 증강 레이어를 포함한 개/고양이 분류 CNN 모델을 생성합니다."""
    model = keras.Sequential([
        layers.Input(shape=input_shape),
        
        # --- 데이터 증강 및 전처리 레이어 ---
        # 픽셀 값을 0~1로 정규화합니다.
        layers.Rescaling(1./255),
        # 50% 확률로 이미지를 수평으로 뒤집습니다.
        layers.RandomFlip("horizontal"),
        # 이미지를 최대 10%까지 무작위로 회전시킵니다.
        layers.RandomRotation(0.1),
        # 이미지를 최대 10%까지 무작위로 확대/축소합니다.
        layers.RandomZoom(0.1),
        
        # --- 특징 추출 블록 ---
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # --- 분류기 ---
        layers.Flatten(),
        layers.Dropout(0.5), # 과적합 방지를 위해 50%의 뉴런을 비활성화
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        # 최종 출력: Sigmoid 함수를 사용하여 0과 1 사이의 확률 값을 출력
        layers.Dense(1, activation='sigmoid')
    ])
    return model
```

### 2.3 모델 컴파일 및 학습

-   **옵티마이저**: `Adam` (효율적인 경사 하강법 알고리즘)
-   **손실 함수**: `BinaryCrossentropy` (두 개의 클래스 간의 확률 분포 차이를 측정하는, 이진 분류에 특화된 손실 함수)
-   **평가 지표**: `Accuracy` (정확도)
-   **에포크(Epochs)**: 50 (전체 훈련 데이터셋을 50번 반복 학습)
-   **총 파라미터 수**: 1,684,705개

### 2.4 학습 결과 및 분석

-   **최종 학습 정확도**: 51.13%
-   **최종 검증 정확도**: 45.50%
-   **모델 파일 크기**: 19.34 MB
-   **분석**: 학습 및 검증 정확도가 50%에 가까워, 모델이 사실상 무작위 추측과 비슷한 성능을 보입니다. 이는 데이터의 양이 부족하거나, 데이터 증강만으로는 해결하기 어려운 복잡한 패턴이 존재함을 시사합니다. 특히, **점진적으로 필터 수를 늘렸다가 다시 줄이는(32 → 64 → 32) 구조**는 파라미터 수를 조절하려는 시도였으나, 성능 향상에는 크게 기여하지 못했습니다. 더 깊은 네트워크나 전이 학습(Transfer Learning)과 같은 고급 기법이 필요함을 알 수 있습니다.

---

## 3. 프로젝트 2: 꽃 이미지 다중 분류

두 번째 프로젝트에서는 5가지 종류의 꽃 이미지를 분류하는 **다중 클래스 분류(Multi-class Classification)** 문제를 다룹니다. 이진 분류와의 차이점과 체계적인 데이터 관리의 중요성에 초점을 맞춥니다.

### 3.1 체계적인 데이터 전처리 및 분할

-   **목표**: 5가지 꽃(daisy, dandelion, rose, sunflower, tulip) 이미지를 분류하는 모델 구축.
-   **데이터**: 총 2,746장의 꽃 이미지.
-   **데이터 관리**: 재사용성과 재현성을 위해 원본 데이터를 직접 수정하지 않고, 전처리 및 분할 스크립트를 통해 새로운 데이터셋을 생성하는 방식을 채택했습니다.
    1.  **이미지 리네이밍**: 각 클래스 폴더 내의 이미지들을 `클래스명.인덱스.확장자` 형식으로 일괄 변경하여 파일명을 표준화합니다. (예: `daisy.1.jpg`)
    2.  **데이터 분할**: 표준화된 전체 데이터셋을 **훈련(50%), 검증(25%), 테스트(25%)** 비율로 분할하여 별도의 디렉토리에 복사합니다. 이를 통해 원본 데이터는 보존하면서, 일관된 학습 및 평가 환경을 구축합니다.

| 클래스 | Train | Validation | Test | 총계 |
| :--- | :--- | :--- | :--- | :--- |
| **Daisy** | 250개 | 125개 | 126개 | 501개 |
| **Dandelion** | 323개 | 161개 | 162개 | 646개 |
| **Rose** | 248개 | 124개 | 125개 | 497개 |
| **Sunflower** | 247개 | 123개 | 125개 | 495개 |
| **Tulip** | 303개 | 151개 | 153개 | 607개 |

### 3.2 다중 분류를 위한 모델 설계

이진 분류 모델의 기본 구조를 재사용하되, 다중 분류 문제에 맞게 출력층과 손실 함수를 수정한 것이 핵심입니다.

```python
# 입력: (180, 180, 3)
def create_multi_flower_model(input_shape=(180, 180, 3), num_classes=5):
    model = keras.Sequential([
        layers.Input(shape=input_shape),
        
        # 데이터 증강 및 전처리 레이어 (프로젝트 1과 동일)
        layers.Rescaling(1./255),
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
        
        # 특징 추출 블록 (프로젝트 1과 동일)
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # 분류기
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        # **[변경점]** 출력층: 5개의 클래스에 대한 확률 분포를 출력하기 위해 뉴런 수를 5로, 활성화 함수를 softmax로 변경
        layers.Dense(num_classes, activation='softmax')
    ])
    
    # **[변경점]** 모델 컴파일
    model.compile(
        optimizer='adam',
        # 손실 함수: 정수 형태의 레이블을 사용하므로 SparseCategoricalCrossentropy 사용
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model
```

### 3.3 학습 결과 및 특징

-   **에포크(Epochs)**: 30
-   **핵심 특징**:
    -   **Softmax 활성화 함수**: 출력층에서 각 클래스에 속할 확률을 0과 1 사이의 값으로 출력하며, 모든 클래스에 대한 확률의 총합은 1이 됩니다.
    -   **체계적인 데이터 관리**: 리네이밍과 분할 스크립트를 통해 데이터 처리 과정을 자동화하고, 실험의 재현성을 확보했습니다.
    -   **정수 레이블 사용**: `image_dataset_from_directory` 유틸리티는 폴더 이름을 기반으로 자동으로 0, 1, 2, 3, 4와 같은 정수 레이블을 생성해주므로, `SparseCategoricalCrossentropy` 손실 함수와 자연스럽게 호환됩니다.

---

## 4. 두 프로젝트 아키텍처 비교 분석

두 프로젝트는 동일한 기본 CNN 구조를 공유하면서도, 해결하려는 문제의 특성에 따라 출력층과 손실 함수에서 명확한 차이를 보입니다.

### 4.1 공통점: 재사용 가능한 CNN 구조

두 모델 모두 다음과 같은 공통적인 아키텍처 패턴을 가집니다. 이는 일반적인 이미지 분류 문제에 효과적으로 적용할 수 있는 범용적인 구조입니다.

-   **기본 구조**: `[Conv2D -> MaxPooling2D]` 블록을 3회 반복하여 계층적으로 특징을 추출합니다.
-   **필터 패턴**: `32 -> 64 -> 32`로 필터 수를 조절하여, 초기에는 다양한 특징을 잡고 중간에 더 복잡한 특징을 학습한 후, 마지막에는 특징을 요약하는 형태를 취합니다.
-   **정규화**: `Dropout(0.5)`를 완전연결층에 적용하여 과적합을 제어합니다.
-   **데이터 증강**: `RandomFlip`, `RandomRotation`, `RandomZoom`을 사용하여 데이터의 다양성을 확보합니다.

### 4.2 차이점: 문제 유형에 따른 모델 변경

| 항목 | 프로젝트 1: 개와 고양이 (이진 분류) | 프로젝트 2: 꽃 (다중 분류) | 이유 및 설명 |
| :--- | :--- | :--- | :--- |
| **문제 유형** | **이진 분류 (Binary Classification)** | **다중 클래스 분류 (Multi-class)** | 두 개의 클래스 중 하나를 선택하는 문제와 여러 클래스 중 하나를 선택하는 문제의 근본적인 차이. |
| **출력층** | `Dense(1, activation='sigmoid')` | `Dense(5, activation='softmax')` | **Sigmoid**: 단일 뉴런이 0~1 사이의 확률(예: '개'일 확률)을 출력.<br>**Softmax**: 5개 뉴런이 각 클래스에 속할 확률을 출력하며, 모든 확률의 합은 1이 됨. |
| **손실 함수** | `BinaryCrossentropy` | `SparseCategoricalCrossentropy` | **BinaryCrossentropy**: 두 개의 확률 분포 간의 차이를 측정.<br>**SparseCategoricalCrossentropy**: 여러 클래스의 확률 분포 간 차이를 측정하며, 레이블이 정수 형태일 때 사용. |
| **클래스 수** | 2개 (개, 고양이) | 5개 (꽃 5종) | 문제에 따라 분류해야 할 대상의 수가 다름. |
| **레이블 형태**| 0 또는 1 | 0, 1, 2, 3, 4 | 이진 분류는 보통 0과 1로, 다중 분류는 0부터 (클래스 수 - 1)까지의 정수로 표현. |

---

## 5. 핵심 기술: 데이터 증강(Data Augmentation)

데이터 증강은 보유한 훈련 데이터에 다양한 변형을 가하여 데이터의 양을 인위적으로 늘리는 기술입니다. 이는 모델이 더 다양한 패턴을 학습하게 하여 과적합을 방지하고 일반화 성능을 향상시키는 데 매우 효과적입니다.

### 5.1 적용된 증강 기법과 그 효과

이번 프로젝트에서는 Keras의 전처리 레이어를 사용하여 실시간으로 이미지에 다음과 같은 변형을 적용했습니다.

```python
from tensorflow import keras
from tensorflow.keras import layers

# 데이터 증강 파이프라인 정의
data_augmentation = keras.Sequential([
    # 1. 픽셀 값 정규화 (증강은 아니지만, 전처리의 일부로 함께 묶음)
    layers.Rescaling(1./255),
    # 2. 수평 뒤집기: 50% 확률로 이미지를 좌우로 뒤집습니다.
    layers.RandomFlip("horizontal"),
    # 3. 무작위 회전: 이미지를 -10% ~ +10% (약 -36도 ~ +36도) 범위에서 무작위로 회전시킵니다.
    layers.RandomRotation(0.1),
    # 4. 무작위 확대/축소: 이미지를 -10% ~ +10% 범위에서 무작위로 확대하거나 축소합니다.
    layers.RandomZoom(0.1),
], name="data_augmentation")
```

| 기법 | 목적 | 기대 효과 |
| :--- | :--- | :--- |
| **RandomFlip** | 좌우 대칭성 학습 | 모델이 객체의 방향에 덜 민감해지도록 만듭니다. (예: 왼쪽을 보는 고양이와 오른쪽을 보는 고양이를 모두 학습) |
| **RandomRotation**| 회전 불변성 학습 | 다양한 각도에서 촬영된 객체를 더 잘 인식하게 됩니다. |
| **RandomZoom** | 크기 불변성 학습 | 이미지 내에서 객체의 크기가 다양하더라도 일관된 특징을 추출할 수 있습니다. |
| **Rescaling** | 수치 안정성 확보 | 모든 픽셀 값을 0~1 사이로 조정하여, 모델의 학습 과정을 안정시키고 수렴 속도를 향상시킵니다. |

### 5.2 데이터 증강의 장점

-   **🛡️ 과적합 방지**: 모델이 훈련 데이터의 특정 패턴에만 과도하게 최적화되는 것을 막아줍니다.
-   **📈 일반화 성능 향상**: 실제 세계에서 마주할 수 있는 다양한 변형(각도, 크기, 방향 등)에 대해 모델이 강건하게 대처할 수 있도록 합니다.
-   **⚡ 실시간 처리**: `ImageDataGenerator`나 Keras의 전처리 레이어는 훈련 중 GPU에서 실시간으로 이미지를 변형하므로, 추가적인 저장 공간이 필요 없습니다.
-   **💾 메모리 효율성**: 원본 데이터의 크기를 그대로 유지하면서 사실상 무한에 가까운 데이터를 생성하는 효과를 냅니다.

---

## 📚 주요 학습 내용

### 1. CNN 기본 구조 이해
```python
# 합성곱층: 특징 추출
Conv2D(filters, kernel_size, activation='relu')

# 풀링층: 다운샘플링
MaxPooling2D(pool_size)

# 완전연결층: 분류 결정
Dense(units, activation)
```

### 2. 이진 분류 vs 다중 분류

| 항목 | 이진 분류 | 다중 분류 |
|------|-----------|-----------|
| **출력 뉴런** | 1개 | 클래스 수만큼 |
| **활성화 함수** | Sigmoid | Softmax |
| **손실 함수** | Binary Crossentropy | Categorical/Sparse Categorical Crossentropy |
| **출력 해석** | 확률 (0~1) | 확률 분포 (합=1) |

### 3. 모델 최적화 기법
- **Dropout**: 과적합 방지를 위한 정규화
- **Adam Optimizer**: 적응적 학습률 조정
- **Data Augmentation**: 데이터 다양성 증대
- **Batch Processing**: 메모리 효율적 학습

### 4. TensorFlow/Keras 활용
```python
# 데이터셋 로딩
train_ds = keras.utils.image_dataset_from_directory(
    directory, validation_split=0.2, subset="training"
)

# 모델 컴파일
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 모델 학습
history = model.fit(train_ds, validation_data=val_ds, epochs=50)

# 모델 저장
model.save('model.keras')
```

---

## 6. 종합 결론 및 향후 과제

### 6.1 주요 학습 성과 요약

이번 두 프로젝트를 통해 다음과 같은 핵심 역량을 체득했습니다.

1.  **CNN 기본 구조 설계**: `Conv2D`, `MaxPooling2D`, `Dense` 레이어를 조합하여 이미지 특징 추출 및 분류를 위한 기본적인 CNN 모델을 직접 설계하고 구현할 수 있게 되었습니다.
2.  **문제 유형별 모델링**: 이진 분류와 다중 분류 문제의 차이점(출력층, 손실 함수)을 명확히 이해하고, 각 문제에 맞는 모델을 적절히 수정하여 적용하는 능력을 갖추었습니다.
3.  **데이터 증강 적용**: 제한된 데이터셋 환경에서 과적합을 완화하고 모델의 일반화 성능을 높이기 위해 데이터 증강 기법을 성공적으로 적용했습니다.
4.  **체계적인 데이터 관리**: 재현성과 효율성을 위해 데이터 리네이밍, 분할, 직렬화 등 체계적인 데이터 전처리 파이프라인의 중요성을 이해하고 직접 구축했습니다.

### 6.2 성능 개선을 위한 다음 단계

현재 모델의 성능을 한 단계 더 발전시키기 위해 다음과 같은 구체적인 과제를 수행할 수 있습니다.

1.  **하이퍼파라미터 튜닝 (Hyperparameter Tuning)**:
    -   **학습률(Learning Rate)**, **배치 크기(Batch Size)**, **에포크 수(Epochs)** 등을 조절하며 최적의 조합을 탐색합니다.
    -   `Adam` 외에 `RMSprop`, `SGD` 등 다른 옵티마이저를 실험하여 성능 변화를 비교 분석합니다.
2.  **고급 모델 아키텍처 도입**:
    -   **전이 학습 (Transfer Learning)**: `VGG16`, `ResNet`, `EfficientNet` 등 ImageNet으로 사전 훈련된 강력한 모델을 기반으로 사용하여, 적은 데이터로도 높은 성능을 달성하는 기법을 적용합니다.
    -   **네트워크 깊이 확장**: `Conv2D` 블록을 더 깊게 쌓아 모델의 표현력을 높이고, 더 복잡한 특징을 학습하도록 유도합니다.
3.  **데이터 품질 및 다양성 향상**:
    -   **추가 데이터 수집**: 더 많고 다양한 데이터를 확보하여 모델의 강건성(Robustness)을 높입니다.
    -   **데이터 불균형 해결**: 클래스 간 데이터 수의 차이가 클 경우, `class_weight` 파라미터를 사용하거나 오버샘플링(SMOTE 등) 기법을 적용합니다.

### 6.3 핵심 인사이트

-   **데이터가 왕이다 (Data is King)**: 모델의 성능은 아키텍처만큼이나 데이터의 양과 질에 크게 좌우됩니다. 체계적인 데이터 관리는 성공적인 프로젝트의 기반입니다.
-   **과적합과의 싸움**: 데이터 증강과 정규화는 단순한 기술이 아닌, CNN 모델링의 필수적인 부분입니다.
-   **실험과 검증의 반복**: 최적의 모델은 한 번에 만들어지지 않습니다. 다양한 하이퍼파라미터와 구조를 실험하고, 검증 데이터로 객관적으로 평가하는 반복 과정이 중요합니다.

---

[⏮️ 이전 문서](./0721_DL정리.md) | [다음 문서 ⏭️](./0723_DL정리.md)