# 🧠 딥러닝 실전: 이진/다중 분류, 회귀 모델 구축 및 평가, 최적화 전략

> 본 문서는 딥러닝 모델을 활용한 이진 분류, 다중 분류, 회귀 문제 해결 과정을 심층적으로 다룹니다. 데이터 전처리부터 모델 설계, 학습, 그리고 성능 평가 및 최적화에 이르는 전반적인 워크플로우를 실제 데이터셋(꽃, 쓰레기, 주택 가격)을 기반으로 상세히 설명합니다. 각 문제 유형별 핵심 개념, 코드 예시, 그리고 실무 적용 가이드를 통해 딥러닝 모델 개발 역량을 강화하는 데 기여합니다.

---

## 목차

1.  [딥러닝 기본 개념](#1-딥러닝-기본-개념)
    *   [1.1 딥러닝이란?](#11-딥러닝이란)
    *   [1.2 문제 유형별 분류](#12-문제-유형별-분류)
    *   [1.3 TensorFlow/Keras 기본 구조](#13-tensorflowkeras-기본-구조)
2.  [데이터 전처리](#2-데이터-전처리)
    *   [2.1 이미지 데이터 전처리 과정](#21-이미지-데이터-전처리-과정)
    *   [2.2 수치 데이터 정규화](#22-수치-데이터-정규화)
    *   [2.3 데이터 분할 전략](#23-데이터-분할-전략)
3.  [이진 분류 (Binary Classification)](#3-이진-분류-binary-classification)
    *   [3.1 이진 분류 모델 설계](#31-이진-분류-모델-설계)
    *   [3.2 핵심 설정 요소](#32-핵심-설정-요소)
    *   [3.3 모델 훈련 및 콜백](#33-모델-훈련-및-콜백)
    *   [3.4 성능 분석](#34-성능-분석)
4.  [다중 분류 (Multi-class Classification)](#4-다중-분류-multi-class-classification)
    *   [4.1 다중 분류 모델 설계](#41-다중-분류-모델-설계)
    *   [4.2 클래스 정의 및 매핑](#42-클래스-정의-및-매핑)
    *   [4.3 데이터 불균형 처리](#43-데이터-불균형-처리)
    *   [4.4 성능 평가](#44-성능-평가)
5.  [회귀 문제 (Regression)](#5-회귀-문제-regression)
    *   [5.1 회귀 모델 설계](#51-회귀-모델-설계)
    *   [5.2 회귀 문제 특성](#52-회귀-문제-특성)
    *   [5.3 데이터셋 분석 및 준비 (California Housing)](#53-데이터셋-분석-및-준비-california-housing)
    *   [5.4 성능 평가 및 결과 분석](#54-성능-평가-및-결과-분석)
6.  [모델 평가 및 최적화](#6-모델-평가-및-최적화)
    *   [6.1 종합 평가 프레임워크](#61-종합-평가-프레임워크)
    *   [6.2 과적합 진단 및 해결](#62-과적합-진단-및-해결)
    *   [6.3 하이퍼파라미터 최적화](#63-하이퍼파라미터-최적화)
    *   [6.4 모델 앙상블](#64-모델-앙상블)
7.  [실무 적용 가이드](#7-실무-적용-가이드)
    *   [7.1 프로젝트 워크플로우: 아이디어에서 운영까지](#71-프로젝트-워크플로우-아이디어에서-운영까지)
    *   [7.2 문제 유형별 적용 사례와 핵심 과제](#72-문제-유형별-적용-사례와-핵심-과제)
    *   [7.3 배포 및 운영 (MLOps의 시작)](#73-배포-및-운영-mlops의-시작)
    *   [7.4 성능 모니터링](#74-성능-모니터링)
    *   [7.5 최신 트렌드 및 발전 방향](#75-최신-트렌드-및-발전-방향)
8.  [학습 정리 및 다음 단계](#8-학습-정리-및-다음-단계)
---

## 1. 딥러닝 기본 개념

### 1.1 딥러닝이란?

**딥러닝(Deep Learning)**은 인공신경망(Artificial Neural Network, ANN)을 여러 층(Layer)으로 깊게 쌓아 올려 데이터 내의 복잡한 패턴을 학습하는 머신러닝의 한 분야입니다. '깊다(Deep)'는 것은 신경망의 은닉층(Hidden Layer)이 여러 개라는 의미이며, 이를 통해 데이터의 추상적인 표현을 계층적으로 학습할 수 있습니다.

#### 핵심 특징

-   **다층 신경망**: 딥러닝 모델은 최소한 하나의 입력층, 하나 이상의 은닉층, 그리고 하나의 출력층으로 구성됩니다. 각 층의 뉴런(노드)들은 서로 연결되어 신호를 전달하며, 이 연결 강도(가중치)를 학습을 통해 조정합니다.
-   **자동 특성 추출 (Automatic Feature Extraction)**: 전통적인 머신러닝 기법과 달리, 딥러닝은 데이터에서 직접적으로 유용한 특성(Feature)을 자동으로 학습하고 추출합니다. 이는 이미지, 음성, 텍스트와 같은 비정형 데이터 처리에서 큰 강점이며, 수동으로 특성을 설계하는 번거로움을 줄여줍니다.
-   **비선형 변환**: 신경망의 각 층에 활성화 함수(Activation Function)를 적용하여 비선형적인 변환을 수행합니다. 이를 통해 딥러닝 모델은 복잡한 비선형 함수 관계를 모델링하고 학습할 수 있게 됩니다.
-   **범용성**: 딥러닝은 분류(Classification), 회귀(Regression), 군집(Clustering)과 같은 전통적인 머신러닝 문제뿐만 아니라, 이미지 생성, 자연어 번역, 음성 인식 등 다양한 복잡한 문제들을 해결하는 데 활용될 수 있습니다.

### 1.2 문제 유형별 분류

딥러닝은 다양한 유형의 문제를 해결할 수 있으며, 문제의 특성에 따라 모델의 출력층 구조, 활성화 함수, 손실 함수 등이 달라집니다. 다음 표는 주요 문제 유형별 딥러닝 모델의 일반적인 설계 패턴을 요약한 것입니다.

| 문제 유형 | 설명 | 출력층 뉴런 수 | 출력층 활성화 함수 | 손실함수 | 실습 예제 |
|:---|:---|:---|:---|:---|:---|
| **이진 분류 (Binary Classification)** | 데이터를 두 개의 상호 배타적인 클래스 중 하나로 분류합니다. (예: 참/거짓, 스팸/정상, 악성/양성) | 1개 | `Sigmoid` | `Binary Crossentropy` | 꽃 분류 (데이지 vs 민들레), 유방암 진단 |
| **다중 분류 (Multi-class Classification)** | 데이터를 세 개 이상의 상호 배타적인 클래스 중 하나로 분류합니다. (예: MNIST 숫자 분류, 붓꽃 품종 분류) | 클래스 수 | `Softmax` | `Categorical Crossentropy` (원-핫 인코딩 라벨) 또는 `Sparse Categorical Crossentropy` (정수 라벨) | 쓰레기 분류 (6개 클래스), MNIST 숫자 분류 |
| **회귀 (Regression)** | 연속적인 수치 값을 예측합니다. (예: 주택 가격, 주식 가격, 온도) | 1개 (단일 값 예측) 또는 예측할 값의 개수 (다중 값 예측) | `Linear` (활성화 함수 없음) | `Mean Squared Error` (MSE) 또는 `Mean Absolute Error` (MAE) | 주택 가격 예측, 주식 가격 예측 |

### 1.3 TensorFlow/Keras 기본 구조

TensorFlow와 Keras는 딥러닝 모델을 구축하고 학습시키는 데 사용되는 핵심 프레임워크입니다. Keras의 `Sequential` API는 층(Layer)을 순서대로 쌓아 올리는 가장 간단하고 직관적인 모델 구성 방법입니다.

```python
# 최신 권장 방식
import tensorflow as tf
from tensorflow.keras import models, layers

# 1. 모델 생성: Sequential API를 사용하여 층을 순서대로 쌓아 올립니다.
model = models.Sequential([
    # 입력층: Input 레이어를 명시적으로 정의하여 모델의 입력 형태를 지정합니다.
    # input_shape은 (특성 수,) 형태로 지정하며, 첫 번째 차원(배치 크기)은 자동으로 처리됩니다.
    layers.Input(shape=(input_dim,)),  # ⭐ 명시적 Input 레이어 사용 권장
    
    # 은닉층: Dense (완전 연결) 층을 추가합니다. 각 뉴런은 이전 층의 모든 뉴런과 연결됩니다.
    # units: 해당 층의 뉴런(노드) 개수
    # activation: 활성화 함수 (예: 'relu', 'tanh')
    layers.Dense(units, activation='relu'),
    
    # 필요에 따라 더 많은 은닉층을 추가할 수 있습니다.
    # layers.Dense(units_2, activation='relu'),
    
    # 출력층: 문제 유형에 맞는 뉴런 수와 활성화 함수를 설정합니다.
    # output_units: 출력 뉴런의 개수 (이진 분류: 1, 다중 분류: 클래스 수, 회귀: 1 또는 예측할 값의 개수)
    # output_activation: 출력층 활성화 함수 (이진 분류: 'sigmoid', 다중 분류: 'softmax', 회귀: 'linear' 또는 없음)
    layers.Dense(output_units, activation='output_activation')
])

# 2. 모델 컴파일: 모델 학습을 위한 설정을 정의합니다.
model.compile(
    optimizer='adam', # 옵티마이저: 모델의 가중치를 업데이트하는 알고리즘 (예: 'adam', 'rmsprop', 'sgd')
    loss='loss_function', # 손실 함수: 모델의 예측과 실제 정답 간의 오차를 측정하는 함수 (예: 'binary_crossentropy', 'categorical_crossentropy', 'mse')
    metrics=['metric'] # 평가지표: 모델의 성능을 측정하는 지표 (예: ['accuracy'], ['mae'])
)

# 모델 요약 정보 출력 (층별 출력 형태, 파라미터 수 등)
model.summary()
```


---

## 2. 데이터 전처리

### 2.1 이미지 데이터 전처리 과정

딥러닝 모델, 특히 이미지 분류 모델은 입력 이미지의 형태와 픽셀 값 범위에 매우 민감합니다. 따라서 모델 학습 전에 이미지를 일관된 형태로 변환하는 전처리 과정이 필수적입니다. 다음은 꽃 분류 실습을 기반으로 한 이미지 전처리 파이프라인의 표준 과정입니다.

#### 이미지 처리 파이프라인 (꽃 분류 실습 기반)

```python
from PIL import Image
import numpy as np
import os

def process_image(image_path, target_size=(80, 80)):
    """단일 이미지 파일을 딥러닝 모델 입력에 적합한 형태로 전처리합니다.

    Args:
        image_path (str): 전처리할 이미지 파일의 경로.
        target_size (tuple): 이미지의 목표 크기 (width, height).

    Returns:
        np.array: 전처리된 이미지의 NumPy 배열 (RGB, 0-255).
    """
    # 1. 이미지 로드: PIL (Pillow) 라이브러리를 사용하여 이미지를 엽니다.
    img = Image.open(image_path)
    
    # 2. RGB 변환: 이미지가 RGB 형식이 아닐 경우 (예: 흑백, RGBA), RGB로 변환합니다.
    # 딥러닝 모델은 일반적으로 3채널 RGB 이미지를 입력으로 받습니다.
    if img.mode != 'RGB':
        img = img.convert('RGB')
    
    # 3. 크기 통일: 모든 이미지를 모델이 요구하는 동일한 크기(target_size)로 조정합니다.
    # 이는 신경망의 입력층 크기를 고정하기 위해 필요합니다.
    img_resized = img.resize(target_size)
    
    # 4. NumPy 배열 변환: PIL Image 객체를 NumPy 배열로 변환합니다.
    # 픽셀 값은 0-255 범위의 정수형으로 유지됩니다.
    pixel_array = np.array(img_resized)
    
    return pixel_array

# --- 사용 예시 ---
# 가상의 이미지 파일 생성 (실제로는 이미지 파일이 있어야 함)
 from PIL import ImageDraw
 dummy_img = Image.new('RGB', (100, 100), color = 'red')
 draw = ImageDraw.Draw(dummy_img)
 draw.text((20, 40), "Hello", fill=(0,0,0))
 dummy_img.save("dummy_image.jpg")

 if os.path.exists("dummy_image.jpg"):
     processed_img = process_image("dummy_image.jpg", target_size=(80, 80))
     print(f"전처리된 이미지 형태: {processed_img.shape}") # (80, 80, 3)
     print(f"전처리된 이미지 픽셀 값 범위: {processed_img.min()} ~ {processed_img.max()}")
 else:
     print("dummy_image.jpg 파일을 찾을 수 없습니다. 실제 이미지 경로를 사용해주세요.")
```

#### 데이터 저장 및 로드 (NPZ 파일 활용)

대량의 이미지를 전처리한 후에는 이를 효율적으로 저장하고 불러올 수 있는 형식을 사용하는 것이 좋습니다. NumPy의 `.npz` 형식은 여러 NumPy 배열을 하나의 압축된 파일로 저장할 수 있어 편리합니다.

```python
# --- 데이터 저장 예시 ---
# images와 labels는 전처리된 이미지 배열과 해당 라벨 리스트라고 가정
 images = np.random.randint(0, 256, size=(10, 80, 80, 3), dtype=np.uint8) # 가상 이미지 데이터
 labels = np.random.randint(0, 2, size=10) # 가상 라벨 데이터

# np.savez() 함수를 사용하여 여러 NumPy 배열을 하나의 .npz 파일로 저장합니다.
# 키-값 쌍 형태로 저장되며, 나중에 키를 통해 데이터를 불러올 수 있습니다.
 np.savez('imagedata0_train.npz', data=images, targets=labels)
 print("imagedata0_train.npz 파일 저장 완료.")

# --- 데이터 로드 예시 ---
# 저장된 .npz 파일을 np.load() 함수를 사용하여 불러옵니다.
# allow_pickle=True는 객체 배열을 포함하는 .npz 파일을 로드할 때 필요할 수 있습니다.
 data_loaded = np.load('imagedata0_train.npz', allow_pickle=True)

# 저장 시 사용했던 키(예: 'data', 'targets')를 사용하여 배열을 추출합니다.
 X_loaded = data_loaded['data']
 y_loaded = data_loaded['targets']

 print(f"\n로드된 이미지 데이터 형태: {X_loaded.shape}")
 print(f"로드된 라벨 데이터 형태: {y_loaded.shape}")
```

### 2.2 수치 데이터 정규화

수치형 데이터는 각 특성(Feature)의 스케일(값의 범위)이 크게 다를 경우, 딥러닝 모델의 학습에 부정적인 영향을 미칠 수 있습니다. 스케일이 큰 특성이 모델 학습에 지배적인 영향을 미치거나, 최적화 과정의 수렴을 방해할 수 있기 때문입니다. 따라서 모델 학습 전에 데이터를 정규화(Normalization) 또는 표준화(Standardization)하는 것이 중요합니다.

#### 정규화의 필요성

**Boston Housing 실습**에서 확인된 스케일 차이:

-   TAX (재산세율): 188 ~ 711 (범위: 523)
-   NOX (질소산화물 농도): 0.39 ~ 0.87 (범위: 0.49)
-   **스케일 차이 비율**: 약 1076:1 (TAX의 범위가 NOX의 범위보다 약 1000배 이상 큼)

이처럼 특성 간 스케일 차이가 클 경우, 경사하강법 기반의 모델은 스케일이 큰 특성에 더 민감하게 반응하여 최적화 경로가 비효율적으로 되거나 수렴이 어려워질 수 있습니다. 따라서 정규화는 필수적인 전처리 과정입니다.

#### 정규화 방법 선택

딥러닝에서 주로 사용되는 정규화 방법은 `StandardScaler` (표준화)와 `MinMaxScaler` (최소-최대 정규화)입니다. `Normalizer`는 주로 텍스트 데이터와 같이 벡터의 방향이 중요한 경우에 사용됩니다.

```python
from sklearn.preprocessing import Normalizer, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_boston # Boston Housing 데이터셋은 scikit-learn 1.2부터 제거됨
import pandas as pd
import numpy as np

# 보스턴 주택가격 데이터셋 로드 (예시를 위해 직접 데이터 생성 또는 다른 데이터셋 사용 권장)
 from sklearn.datasets import fetch_california_housing
 housing = fetch_california_housing()
 X_housing = housing.data
 y_housing = housing.target

# 가상의 데이터 생성 (실제 Boston Housing 데이터셋의 특성 스케일 모방)
np.random.seed(42)
X_dummy = np.random.rand(100, 2) * 100 # 2개 특성
X_dummy[:, 0] = X_dummy[:, 0] * 500 + 100 # TAX 스케일
X_dummy[:, 1] = X_dummy[:, 1] * 0.5 + 0.3 # NOX 스케일
y_dummy = np.random.rand(100)

X_train, X_test, y_train, y_test = train_test_split(X_dummy, y_dummy, test_size=0.3, random_state=42)

print("--- 정규화 전 데이터 스케일 (훈련 데이터) ---")
print(f"TAX (특성 0) 평균: {X_train[:, 0].mean():.2f}, 표준편차: {X_train[:, 0].std():.2f}")
print(f"NOX (특성 1) 평균: {X_train[:, 1].mean():.2f}, 표준편차: {X_train[:, 1].std():.2f}")

# 1. StandardScaler (표준화): 평균을 0, 표준편차를 1로 변환
scaler_std = StandardScaler()
X_train_scaled_std = scaler_std.fit_transform(X_train)
X_test_scaled_std = scaler_std.transform(X_test) # Data Leakage 방지

print("--- StandardScaler 적용 후 데이터 스케일 (훈련 데이터) ---")
print(f"TAX (특성 0) 평균: {X_train_scaled_std[:, 0].mean():.2f}, 표준편차: {X_train_scaled_std[:, 0].std():.2f}")
print(f"NOX (특성 1) 평균: {X_train_scaled_std[:, 1].mean():.2f}, 표준편차: {X_train_scaled_std[:, 1].std():.2f}")

# 2. Normalizer (L2 정규화): 각 샘플(행)의 벡터 크기를 1로 만듦
# 주로 텍스트 분석이나 벡터의 방향이 중요한 경우에 사용
normalizer_l2 = Normalizer(norm='l2')
X_train_normalized_l2 = normalizer_l2.fit_transform(X_train)
X_test_normalized_l2 = normalizer_l2.transform(X_test) # Data Leakage 방지

print("--- Normalizer (L2) 적용 후 데이터 스케일 (훈련 데이터, 첫 5개 샘플의 L2 Norm) ---")
print(np.linalg.norm(X_train_normalized_l2[:5], axis=1))
```


### 2.3 데이터 분할 전략

머신러닝 모델의 성능을 객관적으로 평가하고 과적합(Overfitting)을 방지하기 위해 데이터셋을 훈련(Train) 세트와 테스트(Test) 세트로 분할하는 것은 필수적인 과정입니다. 특히 분류 문제에서는 클래스 불균형을 고려한 분할 전략이 중요합니다.

```python
from sklearn.model_selection import train_test_split
import numpy as np

# 예시 데이터 생성 (클래스 불균형을 가정한 가상 데이터)
X_dummy_split = np.random.rand(100, 5) # 100개 샘플, 5개 특성
y_dummy_split = np.concatenate([np.zeros(80), np.ones(20)]) # 80개 클래스 0, 20개 클래스 1

print("--- 분할 전 클래스 분포 ---")
print(f"클래스 0: {np.sum(y_dummy_split == 0)}개, 클래스 1: {np.sum(y_dummy_split == 1)}개")

# 계층화 분할 (Stratified Split): 타겟 변수(y)의 클래스 비율을 유지하면서 데이터를 분할합니다.
# test_size: 테스트 세트의 비율 (0.3은 30%)
# random_state: 재현성을 위한 난수 시드
# stratify=y: y의 클래스 분포에 따라 계층적으로 분할
X_train, X_test, y_train, y_test = train_test_split(
    X_dummy_split, y_dummy_split, 
    test_size=0.3, 
    random_state=42, 
    stratify=y_dummy_split  # 클래스 분포 균등 유지
)

print("\n--- 분할 후 클래스 분포 (훈련 세트) ---")
print(f"클래스 0: {np.sum(y_train == 0)}개, 클래스 1: {np.sum(y_train == 1)}개")
print("--- 분할 후 클래스 분포 (테스트 세트) ---")
print(f"클래스 0: {np.sum(y_test == 0)}개, 클래스 1: {np.sum(y_test == 1)}개")

print(f"\n훈련 데이터 형태: {X_train.shape}, 훈련 라벨 형태: {y_train.shape}")
print(f"테스트 데이터 형태: {X_test.shape}, 테스트 라벨 형태: {y_test.shape}")
```

---

## 3. 이진 분류 (Binary Classification)

이진 분류는 딥러닝 모델이 데이터를 두 개의 상호 배타적인 클래스 중 하나로 분류하는 문제입니다. 예를 들어, 스팸 메일 분류(스팸/정상), 질병 진단(양성/음성), 제품 불량 여부(불량/정상) 등이 이진 분류에 해당합니다. 여기서는 꽃 분류 실습(데이지 vs 민들레)을 기반으로 이진 분류 모델의 설계, 훈련, 평가 과정을 상세히 살펴봅니다.

### 3.1 이진 분류 모델 설계

이진 분류 모델은 일반적으로 `Sequential` API를 사용하여 여러 개의 `Dense` (완전 연결) 층을 쌓아 올립니다. 출력층은 1개의 뉴런과 `sigmoid` 활성화 함수를 사용하여 0과 1 사이의 확률 값을 출력합니다.

#### 아키텍처 구성 (꽃 분류 실습)

```python
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam # Adam 옵티마이저 임포트

def create_binary_model(input_shape):
    """이진 분류를 위한 신경망 모델을 생성합니다.

    Args:
        input_shape (int): 입력 데이터의 특성(feature) 개수.

    Returns:
        tf.keras.Model: 컴파일된 Sequential 모델 객체.
    """
    model = models.Sequential([
        layers.Input(shape=(input_shape,)),  # 입력층: input_shape를 명시적으로 지정
        layers.Dense(128, activation='relu'), # 첫 번째 은닉층
        layers.Dropout(0.5),  # 과적합 방지를 위한 드롭아웃
        layers.Dense(64, activation='relu'),  # 두 번째 은닉층
        layers.Dropout(0.5),  # 과적합 방지를 위한 드롭아웃
        layers.Dense(32, activation='relu'),  # 세 번째 은닉층
        layers.Dense(1, activation='sigmoid')  # 출력층: 이진 분류를 위해 1개 뉴런, sigmoid 활성화
    ])
    
    # 모델 컴파일: 옵티마이저, 손실 함수, 평가지표 설정
    model.compile(
        optimizer='adam', # Adam 옵티마이저 사용
        loss='binary_crossentropy',  # 이진 분류에 최적화된 손실 함수
        metrics=['accuracy', 'precision', 'recall', 'auc'] # 정확도, 정밀도, 재현율, AUC를 평가지표로 사용
    )
    
    return model

# --- 사용 예시 ---
 input_dim = 784 # 예시 입력 차원 (예: 28x28 이미지 평탄화)
 binary_model = create_binary_model(input_dim)
 binary_model.summary()
```

### 3.2 핵심 설정 요소

이진 분류 모델을 성공적으로 구축하기 위한 핵심 설정 요소들은 다음과 같습니다.

| 구성요소 | 설정 | 이유 |
|:---|:---|:---|
| **출력층** | `layers.Dense(1, activation='sigmoid')` | 이진 분류는 두 클래스 중 하나를 예측하므로 1개의 뉴런을 사용하고, 0과 1 사이의 확률 값을 출력하기 위해 `sigmoid` 활성화 함수를 사용합니다. |
| **손실함수** | `binary_crossentropy` | 이진 분류 문제에 최적화된 손실 함수입니다. 모델의 예측 확률과 실제 라벨(0 또는 1) 간의 오차를 측정합니다. |
| **임계값 (Threshold)** | 0.5 (일반적) | `sigmoid` 출력(확률)이 0.5보다 크면 양성(1), 작으면 음성(0)으로 분류하는 결정 기준입니다. 문제의 특성(예: FP/FN 비용)에 따라 조절할 수 있습니다. |
| **평가지표** | `accuracy`, `precision`, `recall`, `auc` | 모델의 성능을 다각도로 평가하기 위해 정확도 외에 정밀도, 재현율, ROC AUC(Area Under Curve)를 함께 사용합니다. 특히 클래스 불균형이 있는 경우 `precision`, `recall`, `auc`가 중요합니다. |

### 3.3 모델 훈련 및 콜백

모델 훈련은 `model.fit()` 메서드를 사용하여 수행하며, 이 과정에서 `callbacks`를 활용하여 학습 과정을 제어하고 모델의 성능을 최적화할 수 있습니다. `EarlyStopping`과 `ReduceLROnPlateau`는 과적합 방지 및 학습 효율성 증대에 유용한 콜백입니다.

```python
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
import numpy as np

# --- 데이터 준비 (유방암 데이터셋) ---
cancer = load_breast_cancer()
X_data = pd.DataFrame(cancer.data, columns=cancer.feature_names)
y_data = np.where(cancer.target == 0, 1, 0) # 악성을 1, 양성을 0으로 변경

X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_data, y_data, test_size=0.3, random_state=42, stratify=y_data)

scaler_b = StandardScaler()
X_train_scaled_b = scaler_b.fit_transform(X_train_b)
X_test_scaled_b = scaler_b.transform(X_test_b)

# --- 모델 생성 (3.1에서 정의된 create_binary_model 함수 사용) ---
binary_model = create_binary_model(input_shape=X_train_scaled_b.shape[1])

# 콜백 설정
callbacks = [
    # EarlyStopping: val_loss가 10 에포크 동안 개선되지 않으면 학습 중단, 최적 가중치 복원
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1 # 조기 종료 시 메시지 출력
    ),
    # ReduceLROnPlateau: val_loss가 5 에포크 동안 개선되지 않으면 학습률을 0.5배 감소
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=0.00001, # 최소 학습률
        verbose=1 # 학습률 감소 시 메시지 출력
    )
]

print("--- 이진 분류 모델 훈련 시작 ---")
history_binary = binary_model.fit(
    X_train_scaled_b, y_train_b,
    epochs=200, # 충분히 큰 에포크 수 설정 (EarlyStopping이 조절)
    batch_size=32,
    validation_split=0.2, # 훈련 데이터의 20%를 검증 데이터로 사용
    callbacks=callbacks,
    verbose=1
)

print("\n--- 이진 분류 모델 훈련 완료 ---")
```

### 3.4 성능 분석

이진 분류 모델의 성능은 다양한 지표를 통해 종합적으로 분석해야 합니다. 특히 클래스 불균형이 있는 경우 정확도 외의 지표들이 중요합니다.

#### 주요 평가 지표

-   **Accuracy (정확도)**: 전체 예측 중 올바르게 예측한 비율. `(TP + TN) / (TP + TN + FP + FN)`
-   **Precision (정밀도)**: 모델이 '양성'으로 예측한 것 중에서 실제로 '양성'인 비율. `TP / (TP + FP)`
-   **Recall (재현율)**: 실제 '양성'인 것 중에서 모델이 올바르게 '양성'으로 예측한 비율. `TP / (TP + FN)`
-   **AUC (Area Under the ROC Curve)**: ROC 곡선 아래 면적. 모델의 전반적인 분류 성능을 나타내며, 1에 가까울수록 좋은 모델입니다.

#### 실습 결과 (데이지 vs 민들레)

꽃 분류 실습(데이지 vs 민들레)에서 이진 분류 모델을 적용한 결과입니다. (실제 코드는 데이터셋 준비가 복잡하여 생략되었지만, 결과는 다음과 같다고 가정합니다.)

-   최종 테스트 정확도: 약 55%
-   주요 이슈: 데이터 불균형, 모델 복잡도

**분석**: 55%의 정확도는 무작위 예측(50%)보다 약간 나은 수준으로, 모델의 성능이 매우 낮음을 의미합니다. 이는 데이터셋의 특성(예: 데이지와 민들레 이미지 간의 미묘한 차이, 배경 노이즈 등)이나 모델의 복잡도 부족, 또는 데이터 불균형(데이지와 민들레 이미지 수의 차이)과 같은 문제로 인해 발생할 수 있습니다. 특히 이미지 데이터의 경우, 완전 연결 층만으로는 복잡한 시각적 패턴을 학습하기 어렵기 때문에 CNN(Convolutional Neural Network)과 같은 이미지 특화 모델이 필요합니다.


---

## 4. 다중 분류 (Multi-class Classification)

다중 분류는 딥러닝 모델이 데이터를 세 개 이상의 상호 배타적인 클래스 중 하나로 분류하는 문제입니다. 예를 들어, MNIST 숫자 분류(0-9), 붓꽃 품종 분류(3가지 품종), 쓰레기 종류 분류(플라스틱, 유리 등) 등이 다중 분류에 해당합니다. 여기서는 쓰레기 분류 실습을 기반으로 다중 분류 모델의 설계, 데이터 불균형 처리, 성능 평가 과정을 상세히 살펴봅니다.

### 4.1 다중 분류 모델 설계

다중 분류 모델은 일반적으로 `Sequential` API를 사용하여 여러 개의 `Dense` (완전 연결) 층을 쌓아 올립니다. 출력층은 분류할 클래스의 개수만큼의 뉴런과 `softmax` 활성화 함수를 사용하여 각 클래스에 속할 확률 분포를 출력합니다.

#### 쓰레기 분류 모델 (6개 클래스)

```python
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam

def create_multiclass_model(input_shape, num_classes=6):
    """다중 분류를 위한 신경망 모델을 생성합니다.

    Args:
        input_shape (int): 입력 데이터의 특성(feature) 개수.
        num_classes (int): 분류할 클래스의 총 개수.

    Returns:
        tf.keras.Model: 컴파일된 Sequential 모델 객체.
    """
    model = models.Sequential([
        layers.Input(shape=(input_shape,)),  # 입력층: input_shape를 명시적으로 지정
        layers.Dense(512, activation='relu'), # 첫 번째 은닉층
        layers.Dropout(0.3), # 과적합 방지를 위한 드롭아웃
        layers.Dense(256, activation='relu'), # 두 번째 은닉층
        layers.Dropout(0.3),
        layers.Dense(128, activation='relu'), # 세 번째 은닉층
        layers.Dropout(0.2),
        layers.Dense(64, activation='relu'),  # 네 번째 은닉층
        layers.Dropout(0.2),
        layers.Dense(num_classes, activation='softmax')  # 출력층: 클래스 수만큼 뉴런, softmax 활성화
    ])
    
    # 모델 컴파일: 옵티마이저, 손실 함수, 평가지표 설정
    model.compile(
        optimizer='adam', # Adam 옵티마이저 사용
        loss='sparse_categorical_crossentropy',  # 다중 분류 손실 함수 (라벨이 정수 형태일 때)
        metrics=['accuracy'] # 정확도를 평가지표로 사용
    )
    
    return model

# --- 사용 예시 ---
 input_dim_mc = 784 # 예시 입력 차원 (예: 28x28 이미지 평탄화)
 num_classes_mc = 6 # 예시 클래스 수
 multiclass_model = create_multiclass_model(input_dim_mc, num_classes_mc)
 multiclass_model.summary()
```

### 4.2 클래스 정의 및 매핑

다중 분류 문제에서는 각 클래스에 대한 명확한 정의와, 이를 모델이 이해할 수 있는 숫자 ID로 매핑하는 과정이 필요합니다. 이는 모델의 예측 결과를 해석하고 평가하는 데 중요합니다.

#### 쓰레기 분류 데이터셋

쓰레기 분류 데이터셋은 6가지 종류의 쓰레기 카테고리로 구성됩니다. 각 카테고리에는 고유한 ID가 부여됩니다.

| 클래스 ID | 카테고리 | 설명 | 데이터 수 |
|:---|:---|:---|:---|
| 0 | cardboard | 골판지, 박스 | 403개 |
| 1 | glass | 유리병, 유리컵 | 501개 |
| 2 | metal | 캔, 금속 용기 | 410개 |
| 3 | paper | 문서, 신문 | 594개 |
| 4 | plastic | 페트병, 플라스틱 | 482개 |
| 5 | trash | 기타 쓰레기 | 137개 |

```python
# 클래스 이름 정의 (순서는 클래스 ID와 일치해야 함)
class_names_trash = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']

# 클래스 ID와 이름 간의 매핑 딕셔너리 생성
class_id_to_name = {i: name for i, name in enumerate(class_names_trash)}
class_name_to_id = {name: i for i, name in enumerate(class_names_trash)}

print("클래스 ID -> 이름 매핑:", class_id_to_name)
print("클래스 이름 -> ID 매핑:", class_name_to_id)
```

### 4.3 데이터 불균형 처리

다중 분류 문제에서 클래스 간 데이터 수의 차이가 클 경우 **데이터 불균형(Imbalanced Data)** 문제가 발생합니다. 이는 모델이 다수 클래스에 편향되어 소수 클래스의 예측 성능이 저하될 수 있습니다. 쓰레기 분류 데이터셋의 경우, 'paper' 클래스가 594개인 반면 'trash' 클래스는 137개로, 약 4.34:1의 불균형 비율을 보입니다.

#### 불균형 분석

-   최대: 594개 (paper)
-   최소: 137개 (trash)
-   불균형 비율: 4.34:1 (paper:trash)

#### 해결 방안

데이터 불균형 문제를 해결하기 위한 주요 전략들은 다음과 같습니다.

1.  **계층화 분할 (Stratified Split)**: `train_test_split` 함수 사용 시 `stratify=y` 옵션을 설정하여 훈련 세트와 테스트 세트 모두에서 원본 데이터셋의 클래스 비율을 유지합니다. 이는 모델 평가의 신뢰성을 높입니다.
    ```python
    from sklearn.model_selection import train_test_split
    # X_data, y_data는 전체 데이터셋과 라벨
     X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)
    ```
2.  **클래스 가중치 (Class Weight)**: `model.fit()` 메서드의 `class_weight` 매개변수를 사용하여 소수 클래스에 더 높은 가중치를 부여합니다. 이는 모델이 소수 클래스의 샘플을 더 중요하게 학습하도록 유도합니다.
    ```python
    from sklearn.utils import class_weight
    # y_train은 훈련 데이터의 라벨
    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights_dict = dict(enumerate(class_weights))
    # model.fit(..., class_weight=class_weights_dict)
    ```
3.  **데이터 증강 (Data Augmentation)**: 특히 이미지 데이터에서, 부족한 클래스의 이미지를 회전, 확대/축소, 뒤집기 등 인위적으로 변형하여 데이터의 양을 늘립니다.
4.  **리샘플링 (Resampling)**: 
    -   **오버샘플링 (Oversampling)**: 소수 클래스의 샘플 수를 늘립니다. (예: SMOTE)
    -   **언더샘플링 (Undersampling)**: 다수 클래스의 샘플 수를 줄입니다.

### 4.4 성능 평가

다중 분류 모델의 성능은 정확도 외에 클래스별 정밀도, 재현율, F1-score 등을 종합적으로 분석해야 합니다. 혼동 행렬은 모델의 예측 오류 유형을 시각적으로 파악하는 데 매우 유용합니다.

#### 혼동 행렬 분석

```python
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --- 가상 데이터 및 모델 예측 (실제로는 모델 학습 후 예측 결과 사용) ---
# X_test_mc, y_test_mc는 테스트 데이터와 실제 라벨
# multiclass_model은 학습된 다중 분류 모델
 y_pred_mc_proba = multiclass_model.predict(X_test_mc) # 모델의 예측 확률
 y_pred_classes_mc = np.argmax(y_pred_mc_proba, axis=1) # 가장 높은 확률을 가진 클래스 선택

# 가상 예측 결과 생성 (실제 쓰레기 분류 데이터셋의 클래스 수에 맞춤)
y_test_mc_dummy = np.array([0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5])
y_pred_classes_mc_dummy = np.array([0, 1, 2, 3, 4, 5, 1, 0, 3, 2, 5, 4, 0, 1, 2, 3, 4, 5])
class_names_trash = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']

# 혼동 행렬 계산
cm_mc = confusion_matrix(y_test_mc_dummy, y_pred_classes_mc_dummy)
print("--- 혼동 행렬 (Confusion Matrix) ---")
print(cm_mc)

# 혼동 행렬 시각화
plt.figure(figsize=(10, 8))
sns.heatmap(cm_mc, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names_trash, yticklabels=class_names_trash)
plt.title('쓰레기 분류 혼동 행렬')
plt.ylabel('실제 레이블')
plt.xlabel('예측 레이블')
plt.show()

# 분류 보고서
print("\n--- 분류 보고서 (Classification Report) ---")
print(classification_report(y_test_mc_dummy, y_pred_classes_mc_dummy, 
                          target_names=class_names_trash))
```

#### 실습 결과 (쓰레기 분류)

쓰레기 분류 모델의 최종 성능은 다음과 같습니다. (실제 실행 결과는 모델 학습 및 데이터에 따라 달라질 수 있습니다.)

-   전체 정확도: 54.9%
-   클래스별 성능 편차 존재:
    -   Trash 클래스: 높은 정밀도(1.00), 낮은 재현율(0.12) → 모델이 Trash라고 예측하면 거의 맞지만, 실제 Trash를 잘 찾아내지 못함 (많은 Trash를 다른 클래스로 오분류)

**분석**: 전체 정확도가 54.9%로 낮은 편이며, 특히 'trash' 클래스에서 재현율이 매우 낮게 나타났습니다. 이는 'trash' 클래스의 데이터 수가 다른 클래스에 비해 현저히 적기 때문에 발생하는 데이터 불균형 문제의 전형적인 예시입니다. 모델이 'trash' 클래스를 충분히 학습하지 못하여 다른 클래스로 오분류하는 경향이 강합니다. 이러한 문제를 해결하기 위해서는 클래스 가중치 부여, 데이터 증강, 리샘플링(SMOTE 등)과 같은 데이터 불균형 처리 기법을 적용해야 합니다.


---

## 5. 회귀 문제 (Regression)

회귀는 딥러닝 모델이 **연속적인 수치 값을 예측**하는 문제입니다. 주택 가격, 주식 시세, 수요량, 온도 등 다양한 분야에서 활용됩니다. 분류 문제와 핵심적인 차이점은 다음과 같습니다.

-   **출력**: 클래스 레이블이 아닌, 임의의 연속적인 값(예: 25.6, 150000, -10.2)을 출력합니다.
-   **출력층 활성화 함수**: 특정 범위(예: 0~1)로 값을 제한할 필요가 없으므로, 활성화 함수를 사용하지 않거나(`linear`) ReLU를 사용하여 음수 출력을 방지하는 등 문제에 맞게 선택합니다.
-   **손실 함수**: 예측값과 실제값의 차이를 측정하는 `MSE`(Mean Squared Error, 평균 제곱 오차) 또는 `MAE`(Mean Absolute Error, 평균 절대 오차)를 주로 사용합니다.
-   **평가 지표**: `Accuracy` 대신 `MAE`, `RMSE`(Root Mean Squared Error), `R²`(결정 계수) 등을 사용하여 모델의 예측 정확도를 평가합니다.

### 5.1 회귀 모델 설계

회귀 모델은 일반적으로 `Sequential` API를 사용하여 여러 개의 `Dense` 층을 쌓아 올립니다. 출력층은 예측하려는 값의 수(보통 1개)에 맞춰 뉴런 수를 정하고, 활성화 함수는 대부분 사용하지 않습니다.

#### California Housing 가격 예측 모델

> **참고**: 과거에는 Boston Housing 데이터셋이 많이 사용되었으나, 인종차별적 데이터가 포함되어 있어 현재는 사용이 지양됩니다. `scikit-learn` 1.2 버전부터는 해당 데이터셋이 삭제되었으며, **California Housing** 데이터셋이 대체재로 널리 사용됩니다.

```python
from tensorflow.keras import models, layers

def create_regression_model(input_shape):
    """회귀 예측을 위한 신경망 모델을 생성합니다.

    Args:
        input_shape (tuple): 입력 데이터의 특성 형태.

    Returns:
        tf.keras.Model: 컴파일된 Sequential 모델 객체.
    """
    model = models.Sequential([
        layers.Input(shape=input_shape),
        layers.Dense(128, activation='relu', kernel_initializer='he_normal'),
        layers.Dense(64, activation='relu', kernel_initializer='he_normal'),
        layers.Dense(32, activation='relu', kernel_initializer='he_normal'),
        layers.Dense(1)  # 출력층: 단일 연속 값 예측, 활성화 함수 없음 (Linear)
    ])
    
    model.compile(
        optimizer='adam',
        loss='mse',      # 손실 함수: 평균 제곱 오차
        metrics=['mae']  # 평가지표: 평균 절대 오차
    )
    
    return model

# 예시: California Housing 데이터셋은 8개의 특성을 가짐
input_shape_reg = (8,)
regression_model = create_regression_model(input_shape_reg)
regression_model.summary()
```

### 5.2 회귀 문제 특성

#### 분류 vs 회귀 심층 비교

| 특성 | 분류 (Classification) | 회귀 (Regression) |
| :--- | :--- | :--- |
| **목표** | 데이터가 속할 **카테고리** 예측 | 데이터의 **연속적인 수치** 예측 |
| **출력값** | 클래스 확률 분포 (예: [0.1, 0.9]) | 실제 숫자 (예: 25.4) |
| **출력층 활성화** | `sigmoid` (이진), `softmax` (다중) | `linear` (없음) 또는 `relu` (양수만) |
| **손실 함수** | `binary/categorical_crossentropy` | `mse`, `mae`, `huber_loss` |
| **핵심 평가지표** | `Accuracy`, `Precision`, `Recall`, `F1-score`, `AUC` | `MAE`, `MSE`, `RMSE`, `R²` (R-squared) |
| **결과 해석** | "이 이미지는 90% 확률로 고양이입니다." | "이 집의 예상 가격은 $254,000입니다." |

### 5.3 데이터셋 분석 및 준비 (California Housing)

California Housing 데이터셋은 캘리포니아의 각 블록 그룹에 대한 8개의 특성과 중간 주택 가격(타겟)으로 구성됩니다.

####  EDA (탐색적 데이터 분석) 및 전처리

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. 데이터 로드
housing = fetch_california_housing()
X = pd.DataFrame(housing.data, columns=housing.feature_names)
y = housing.target # 타겟: 중간 주택 가격 ($100,000 단위)

# 2. 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 특성 스케일링 (StandardScaler 사용)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test) # 훈련 데이터 기준으로 테스트 데이터 변환

# 4. 타겟 분포 확인 (시각화)
plt.figure(figsize=(10, 6))
sns.histplot(y_train, kde=True, bins=30)
plt.title('Distribution of Median House Value (Training Data)')
plt.xlabel('Median House Value ($100,000s)')
plt.ylabel('Frequency')
plt.show()

print("--- 데이터 준비 완료 ---")
print(f"훈련 데이터 형태: {X_train_scaled.shape}")
print(f"테스트 데이터 형태: {X_test_scaled.shape}")
```

### 5.4 성능 평가 및 결과 분석

회귀 모델의 성능은 예측값과 실제값의 차이를 기반으로 한 지표들을 통해 다각적으로 평가해야 합니다.

#### 주요 평가 지표 상세

-   **MAE (Mean Absolute Error)**: `Σ|y_true - y_pred| / n`
    -   **의미**: 예측 오차의 절댓값 평균. 직관적이고 해석하기 쉽습니다. (예: MAE가 0.5이면 평균적으로 $50,000 오차가 발생)
-   **MSE (Mean Squared Error)**: `Σ(y_true - y_pred)² / n`
    -   **의미**: 오차를 제곱하여 평균. 큰 오차에 더 큰 페널티를 부여합니다. 훈련 과정에서 손실 함수로 주로 사용됩니다.
-   **RMSE (Root Mean Squared Error)**: `sqrt(MSE)`
    -   **의미**: MSE에 루트를 씌워 원래 타겟과 같은 단위로 만듭니다. MAE와 함께 모델 성능을 실제 단위로 해석하는 데 유용합니다.
-   **R² (결정 계수)**: `1 - (Σ(y_true - y_pred)²) / (Σ(y_true - y_mean)²) `
    -   **의미**: 모델이 데이터의 분산을 얼마나 잘 설명하는지를 나타냅니다. 1에 가까울수록 모델이 데이터를 잘 설명한다는 뜻입니다.

#### 모델 훈련 및 평가 코드

```python
import tensorflow as tf

# 모델 생성 (5.1에서 정의한 함수 사용)
model = create_regression_model(input_shape=(X_train_scaled.shape[1],))

# 조기 종료 콜백
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# 모델 훈련
history = model.fit(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping],
    verbose=0 # 훈련 과정 출력 생략
)

# 성능 평가
loss, mae = model.evaluate(X_test_scaled, y_test, verbose=0)
mse = model.evaluate(X_test_scaled, y_test, verbose=0)[0] # loss가 mse
rmse = np.sqrt(mse)

print(f"--- 테스트 세트 성능 ---")
print(f"MAE: {mae:.4f} (평균적으로 약 ${mae*100000:,.0f}의 가격 오차)")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")

# R² 계산
from sklearn.metrics import r2_score
y_pred = model.predict(X_test_scaled).flatten()
r2 = r2_score(y_test, y_pred)
print(f"R² (결정 계수): {r2:.4f}")
```

#### 결과 시각화

모델의 예측 성능을 직관적으로 파악하기 위해 **실제값 vs 예측값 산점도**와 **잔차(Residuals) 분포**를 시각화하는 것이 매우 중요합니다.

```python
# 1. 실제값 vs 예측값 산점도
plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r', lw=2) # y=x 기준선
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values (R²: {:.4f})".format(r2))
plt.grid(True)
plt.show()

# 2. 잔차(오차) 분포
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True, bins=30)
plt.xlabel("Prediction Error (Residuals)")
plt.title("Distribution of Prediction Errors")
plt.axvline(0, color='red', linestyle='--')
plt.show()
```

**분석**:
-   **산점도**: 점들이 빨간 점선(y=x)에 가까이 분포할수록 모델의 예측이 정확함을 의미합니다.
-   **잔차 분포**: 잔차(오차)가 0을 중심으로 정규분포에 가까운 형태를 보일 때, 모델이 데이터의 패턴을 잘 학습했다고 해석할 수 있습니다.

---

## 6. 모델 평가 및 최적화

모델을 훈련하는 것만큼이나 중요한 것은 **객관적인 성능 평가**와 **지속적인 최적화**입니다. 이 단계에서는 모델의 신뢰도를 확보하고, 과적합과 같은 일반적인 문제를 해결하며, 최상의 성능을 이끌어내는 방법을 다룹니다.

### 6.1 종합 평가 프레임워크

문제 유형에 따라 적합한 평가지표와 시각화 방법을 선택하는 것이 중요합니다.

| 문제 유형 | 핵심 평가지표 | 보조 지표 및 고려사항 | 추천 시각화 |
| :--- | :--- | :--- | :--- |
| **이진 분류** | **AUC**, **F1-Score** | `Accuracy` (클래스가 균등할 때), `Precision`, `Recall` (FP/FN 비용에 따라 중요도 조절) | ROC Curve, Precision-Recall Curve, 혼동 행렬 |
| **다중 분류** | **Macro/Weighted F1-Score** | `Accuracy`, 클래스별 `Precision` & `Recall` (데이터 불균형 시 필수 확인) | 혼동 행렬(히트맵), 클래스별 성능 막대그래프 |
| **회귀** | **RMSE**, **MAE** | `R²`(모델의 설명력), 타겟의 스케일에 따른 지표의 상대적 크기 | 실제값 vs 예측값 산점도, 잔차(Residuals) 분포도 |

### 6.2 과적합 진단 및 해결

**과적합(Overfitting)**은 모델이 훈련 데이터에만 지나치게 최적화되어, 새로운 데이터(검증/테스트 데이터)에 대한 일반화 성능이 떨어지는 현상입니다.

#### 과적합 진단

과적합은 주로 **훈련 손실(loss)과 검증 손실(validation loss)의 차이**를 통해 진단합니다.

```python
# history 객체를 사용한 손실 곡선 시각화
def plot_loss_curves(history):
    plt.figure(figsize=(12, 5))
    
    # 훈련/검증 손실
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training vs. Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    
    # 훈련/검증 정확도 (또는 MAE 등)
    # 'accuracy' 키가 있는지 확인
    if 'accuracy' in history.history:
        plt.subplot(1, 2, 2)
        plt.plot(history.history['accuracy'], label='Training Accuracy')
        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training vs. Validation Accuracy')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()

    plt.tight_layout()
    plt.show()

plot_loss_curves(history) # model.fit()에서 반환된 history 객체 전달
```

**과적합 징후**:
-   훈련 손실은 계속 감소하지만, 검증 손실은 어느 시점부터 상승하거나 정체됩니다.
-   두 손실 곡선 사이의 간격(gap)이 점점 벌어집니다.

#### 해결 전략 (Regularization)

과적합을 완화하는 기법을 **규제(Regularization)**라고 합니다. 다음은 주요 규제 기법들을 통합적으로 적용한 모델의 예시입니다.

```python
from tensorflow.keras import layers, models, regularizers, callbacks
# ... (데이터가 X_train_scaled, y_train 등으로 준비되었다고 가정)

def create_regularized_model(input_shape):
    """다양한 규제 기법이 적용된 회귀 모델을 생성합니다."""
    model = models.Sequential([
        layers.Input(shape=input_shape),
        
        # 첫 번째 Dense 블록: L2 규제, 배치 정규화, 드롭아웃 적용
        layers.Dense(128, kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(), # 활성화 함수 이전에 적용
        layers.Activation('relu'),
        layers.Dropout(0.5), # 50%의 뉴런을 비활성화

        # 두 번째 Dense 블록
        layers.Dense(64, kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.Dropout(0.3), # 30%의 뉴런을 비활성화

        # 출력층
        layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# 모델 생성
 regularized_model = create_regularized_model((X_train_scaled.shape[1],))

# 콜백 정의
# 1. 조기 종료: 검증 손실이 10 에포크 동안 개선되지 않으면 훈련 중단 및 최적 가중치 복원
early_stopping_cb = callbacks.EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True)
# 2. 학습률 감소: 검증 손실이 5 에포크 동안 개선되지 않으면 학습률을 절반으로 줄임
reduce_lr_cb = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

# 모델 훈련 시 콜백 전달
 history_regularized = regularized_model.fit(
     X_train_scaled, y_train,
     epochs=200, # 조기 종료가 있으므로 충분히 길게 설정
     batch_size=32,
     validation_split=0.2,
     callbacks=[early_stopping_cb, reduce_lr_cb],
     verbose=0 # 훈련 과정 로그 생략
 )
 print("Regularized model training complete.")
 plot_loss_curves(history_regularized)
```

### 6.3 하이퍼파라미터 최적화

**하이퍼파라미터**는 모델이 학습을 통해 스스로 찾는 파라미터(가중치, 편향)가 아닌, 개발자가 직접 설정해야 하는 값들입니다. (예: 학습률, 배치 크기, 층의 수 등)

#### 튜닝 전략: Keras Tuner

Keras Tuner는 `RandomSearch`, `Hyperband`, `BayesianOptimization` 등 다양한 알고리즘을 통해 최적의 하이퍼파라미터 조합을 효율적으로 탐색합니다.

```python
import keras_tuner as kt

def build_model_for_tuner(hp):
    model = models.Sequential()
    model.add(layers.Input(shape=(X_train_scaled.shape[1],)))
    
    # 뉴런 수 탐색 (32 ~ 256, 32 간격)
    hp_units = hp.Int('units', min_value=32, max_value=256, step=32)
    model.add(layers.Dense(units=hp_units, activation='relu'))
    
    # 드롭아웃 비율 탐색 (0.0 ~ 0.5)
    model.add(layers.Dropout(hp.Float('dropout', 0.0, 0.5, step=0.1)))
    
    model.add(layers.Dense(1)) # 회귀 문제의 출력층
    
    # 학습률 탐색
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])
    
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),
                  loss='mse', metrics=['mae'])
    return model

# Hyperband 튜너 설정
 tuner = kt.Hyperband(build_model_for_tuner,
                      objective='val_mae', # 최소화할 목표 지표
                      max_epochs=50,
                      factor=3, # 각 라운드에서 모델 수를 1/3로 줄임
                      directory='tuning_dir',
                      project_name='housing_price_tuning')

# 최적 하이퍼파라미터 탐색
 tuner.search(X_train_scaled, y_train, validation_split=0.2,
              callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])

# 최적의 하이퍼파라미터 확인
 best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
 print(f"Best learning rate: {best_hps.get('learning_rate')}")
 print(f"Best units: {best_hps.get('units')}")

# 최적의 모델로 최종 훈련
 final_model = tuner.hypermodel.build(best_hps)
 final_model.fit(...)
```

### 6.4 모델 앙상블

**앙상블(Ensemble)**은 여러 개의 다른 모델을 만들어 그 예측을 결합함으로써, 단일 모델보다 더 강건하고 정확한 예측을 하는 기법입니다.

-   **작동 원리**: 서로 다른 모델들이 만든 오차는 서로 다를 가능성이 높습니다. 이 오차들을 평균내거나 다수결로 결정하면 상쇄되어 전체적인 성능이 향상됩니다.
-   **앙상블을 위한 모델 다양성 확보 방법**:
    1.  서로 다른 초기 가중치로 같은 구조의 모델을 여러 번 훈련.
    2.  서로 다른 하이퍼파라미터(구조, 학습률 등)를 가진 모델들을 훈련.
    3.  서로 다른 종류의 모델(예: 신경망, XGBoost, LightGBM)을 결합.

#### 평균 기반 앙상블 (Averaging Ensemble) 예시

가장 간단하면서도 효과적인 앙상블 방법 중 하나는 여러 모델의 예측값을 산술 평균하는 것입니다.

```python
import numpy as np
from sklearn.metrics import mean_absolute_error

# 가정: X_train_scaled, y_train, X_test_scaled, y_test가 준비되어 있음
# 가정: create_regression_model 함수가 5.1 섹션에 정의되어 있음

# 1. 여러 개의 모델 생성 및 훈련
num_models = 5
models_list = []
for i in range(num_models):
    print(f"Training model {i+1}/{num_models}...")
    # 매번 새로운 가중치로 초기화된 모델 생성
    model = create_regression_model((X_train_scaled.shape[1],))
    model.fit(X_train_scaled, y_train,
              epochs=100,
              batch_size=32,
              validation_split=0.2,
              callbacks=[callbacks.EarlyStopping(patience=10, monitor='val_loss')],
              verbose=0)
    models_list.append(model)
    _, single_mae = model.evaluate(X_test_scaled, y_test, verbose=0)
    print(f"Model {i+1} MAE: {single_mae:.4f}")

# 2. 각 모델의 예측 수행 및 결합
predictions_list = [model.predict(X_test_scaled) for model in models_list]

# 3. 예측값 평균
# predictions_list는 (num_models, num_test_samples, 1) 형태의 리스트
# 이를 (num_test_samples, num_models) 형태로 변환하여 평균 계산
ensemble_predictions = np.mean(np.hstack(predictions_list), axis=1)

# 4. 앙상블 성능 평가
ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)

print(f"\nEnsemble MAE: {ensemble_mae:.4f}")
```

---

## 7. 실무 적용 가이드

이론과 실습을 넘어, 딥러닝 모델을 실제 가치로 연결하기 위한 실무 가이드를 제공합니다.

### 7.1 프로젝트 워크플로우: 아이디어에서 운영까지

딥러닝 프로젝트는 일회성 개발이 아닌, 지속적인 개선이 필요한 **반복적인 생명주기(Lifecycle)**를 가집니다.

```mermaid
graph LR
    subgraph Phase 1: 기획 및 설계
        A[1. 문제 정의 & 목표 설정] --> B[2. 데이터 확보 및 탐색(EDA)]
    end
    subgraph Phase 2: 개발 및 실험
        B --> C[3. 데이터 전처리 & 특성 공학]
        C --> D[4. 기준(Baseline) 모델 수립]
        D --> E[5. 모델 훈련 및 하이퍼파라미터 튜닝]
        E --> F[6. 성능 평가 및 오류 분석]
    end
    subgraph Phase 3: 배포 및 운영
        F -- 성능 만족? --> G[7. 모델 배포 및 서빙]
        G --> H[8. 성능 모니터링 및 재학습]
    end
    F -- 성능 부족 --> E
    H -- 드리프트 감지/성능 저하 --> B
```

-   **1. 문제 정의 & 목표 설정**: 비즈니스 문제를 딥러닝 문제(분류/회귀)로 명확히 변환하고, 성공을 측정할 핵심 지표(KPI)를 설정합니다. (예: "주택 가격 예측 MAE를 $35,000 이하로 낮춘다.")
-   **4. 기준(Baseline) 모델 수립**: 복잡한 모델을 시도하기 전에, 간단한 모델(예: `LinearRegression`, 얕은 신경망)로 최소 성능의 기준점을 설정합니다. 이는 이후 모델 개선의 효과를 측정하는 척도가 됩니다.
-   **6. 오류 분석 (Error Analysis)**: 전체 성능 지표만 보지 않고, 모델이 어떤 종류의 데이터에서 주로 틀리는지 심층 분석합니다. (예: "유독 침실 수가 5개 이상인 비싼 주택에서 오차가 크다.")
-   **8. 모니터링 및 재학습**: 배포된 모델의 성능은 영원하지 않습니다. 데이터 분포의 변화(Drift)를 지속적으로 감지하고, 성능이 일정 수준 이하로 떨어지면 자동으로 재학습하는 파이프라인(MLOps)을 구축하는 것이 중요합니다.

### 7.2 문제 유형별 적용 사례와 핵심 과제

| 분야 | 적용 사례 | 문제 유형 | 핵심 과제 (Key Challenges) |
| :--- | :--- | :--- | :--- |
| **금융** | 신용카드 사기 탐지 | 이진 분류 | 극심한 데이터 불균형, 실시간 추론(Low Latency) 요구 |
| **제조** | 반도체 웨이퍼 불량 탐지 | 다중 분류 | 적은 불량 데이터, 비정형 이미지 데이터 처리, 설명 가능성(XAI) |
| **의료** | MRI 기반 종양 악성/양성 판별 | 이진 분류 | 데이터 프라이버시, 데이터 부족, 모델의 신뢰성 및 안전성 |
| **E-커머스**| 고객의 다음 달 구매액 예측 | 회귀 | 복잡한 시계열 특성, 외부 요인(프로모션, 계절) 반영, 특성 공학 |

### 7.3 배포 및 운영 (MLOps의 시작)

훈련된 모델을 실제 서비스에서 사용 가능하도록 만드는 과정을 **배포(Deployment)**라고 합니다.

####  모델 배포 전략: 간단한 REST API 서버 구축

`Flask`와 `joblib`을 사용하여 모델과 전처리기를 서빙하는 간단한 API 예시입니다.

```python
# app.py
from flask import Flask, request, jsonify
import tensorflow as tf
import joblib
import numpy as np

app = Flask(__name__)

# 서버 시작 시 모델과 스케일러 로드
try:
    model = tf.keras.models.load_model('final_model.keras', compile=False)
    scaler = joblib.load('standard_scaler.pkl')
    print("Model and scaler loaded successfully.")
except Exception as e:
    print(f"Error loading model or scaler: {e}")
    model, scaler = None, None

@app.route('/predict', methods=['POST'])
def predict():
    if not model or not scaler:
        return jsonify({"error": "Model is not available."}), 500

    try:
        # JSON 요청에서 데이터 추출
        data = request.get_json()
        # 입력 데이터는 2D 배열 형태여야 함 (예: [[...]])
        features = np.array(data['features'])

        # 데이터 스케일링
        scaled_features = scaler.transform(features)

        # 예측 수행
        prediction = model.predict(scaled_features)

        # 결과 반환
        return jsonify({'predicted_value': prediction.flatten().tolist()})

    except Exception as e:
        return jsonify({"error": str(e)}), 400

# 서버 실행 (예: python app.py)
# if __name__ == '__main__':
#     app.run(debug=True, port=5000)
```

### 7.4 성능 모니터링

배포된 모델은 시간이 지나면서 성능이 저하될 수 있으므로, 지속적인 모니터링이 필수입니다.

-   **데이터 드리프트 (Data Drift)**: 실제 운영 환경의 데이터 분포가 훈련 시점의 데이터 분포와 달라지는 현상. (예: 계절 변화로 인한 소비자 행동 패턴 변화)
-   **개념 드리프트 (Concept Drift)**: 데이터의 특성과 타겟 변수 간의 관계 자체가 변하는 현상. (예: 새로운 금융 정책으로 인한 대출 심사 기준 변경)
-   **모니터링 방안**: 운영 데이터의 통계량을 주기적으로 계산하여 훈련 데이터와 비교하고, 모델의 예측 성능(MAE, F1-score 등)을 지속적으로 추적하여 성능 저하가 감지되면 모델 재학습을 트리거합니다.

### 7.5 최신 트렌드 및 발전 방향

-   **트랜스포머의 부상**: 자연어 처리를 넘어 컴퓨터 비전(Vision Transformer), 시계열 예측 등 다양한 도메인에서 SOTA(State-of-the-art) 성능을 달성하고 있습니다.
-   **생성형 AI (Generative AI)**: `GANs`, `Diffusion Models` 등을 기반으로 이미지, 텍스트, 오디오를 생성하는 기술이 급격히 발전하고 있습니다. (예: DALL-E, Stable Diffusion, GPT)
-   **MLOps (Machine Learning Operations)**: 모델 개발, 배포, 운영의 전 과정을 자동화하고 효율화하는 문화 및 기술 스택의 중요성이 부각되고 있습니다.
-   **XAI (Explainable AI)**: `SHAP`, `LIME`과 같은 기법을 통해 "블랙박스"로 여겨졌던 딥러닝 모델의 예측 근거를 설명하려는 연구가 활발합니다.

---

## 8. 학습 정리 및 다음 단계

1.  **문제 정의 및 모델링 역량**
    -   비즈니스 요구사항을 분석하여 **이진 분류, 다중 분류, 회귀** 중 적합한 문제로 정의할 수 있습니다.
    -   문제 유형에 맞는 Keras 모델 구조, 손실 함수, 평가지표를 **스스로 설계하고 선택**할 수 있습니다.

2.  **End-to-End 구현 및 개발 역량**
    -   `TensorFlow`와 `scikit-learn`을 활용하여 데이터 로딩, 정규화, 분할부터 모델 훈련 및 평가까지 **전체 파이프라인을 코드로 구현**할 수 있습니다.
    -   이미지 및 정형 데이터를 모델 입력에 맞게 **효과적으로 전처리**하는 기술을 습득했습니다.

3.  **모델 성능 최적화 및 문제 해결 역량**
    -   훈련/검증 손실 곡선을 시각화하여 **과적합을 진단**하고, `Dropout`, `L2 규제`, `조기 종료` 등 상황에 맞는 규제 기법을 적용하여 **모델의 일반화 성능을 향상**시킬 수 있습니다.
    -   `Keras Tuner`를 활용하여 주요 하이퍼파라미터를 **자동으로 탐색하고 최적화**하는 프로세스를 수행할 수 있습니다.
    -   데이터 불균형, 특성 스케일 차이 등 실전 데이터에서 발생하는 **핵심 문제들을 인식하고 해결**할 수 있습니다.

#### 다음 학습 추천: 성장 로드맵

```mermaid
graph TD
    subgraph "Stage 1: Foundation (현재 위치)"
        A[딥러닝 기초 및<br>핵심 문제 유형 정복<br>(본 문서)]
    end

    subgraph "Stage 2: Specialization (심화 학습)"
        A --> B{도메인 선택}
        B --> C[<b>컴퓨터 비전 (CV)</b><br>CNN, ResNet, YOLO, ViT]
        B --> D[<b>자연어 처리 (NLP)</b><br>RNN, LSTM, Attention, Transformer, BERT]
        B --> E[<b>시계열 / 추천시스템</b><br>LSTM, GRU, Facebook Prophet]
    end

    subgraph "Stage 3: Advanced & Applied (고급 및 응용)"
        C --> F[<b>고급 CV</b><br>GANs, Diffusion Models, NeRF]
        D --> G[<b>고급 NLP</b><br>LLMs, RAG, Fine-tuning]
        E --> H[<b>고급 시계열/추천</b><br>Transformer-based models]
    end
    
    subgraph "Stage 4: Professionalization (전문가 과정)"
        F & G & H --> I[실무 프로젝트 & Kaggle<br>포트폴리오 구축]
        I --> J[<b>MLOps 역량 강화</b><br>Docker, CI/CD, MLflow, Cloud AI]
    end
```

---

[⏮️ 이전 문서](./0717_DL정리.md) | [다음 문서 ⏭️](./0721_DL정리.md)