<h2>머신러닝 모델 비교 분석: 회귀, 분류, 그리고 이미지 인식</h2>
작성자: Alpine_Dolce&nbsp;&nbsp;|&nbsp;&nbsp;날짜: 2025-07-08

<h2>문서 목표</h2>
본 문서는 다양한 머신러닝 회귀 및 분류 모델의 성능을 비교 분석하고, 실제 이미지 분류 프로젝트(꽃 분류 시스템)를 통해 데이터 처리부터 모델 평가, 그리고 성능 개선 방안까지의 전 과정을 상세히 다룹니다.

<h2>목차</h2>

- [1. 회귀 분석 모델 비교: 당뇨병 예측](#1-회귀-분석-모델-비교-당뇨병-예측)
  - [데이터셋 소개](#데이터셋-소개)
  - [회귀 모델별 성능 분석](#회귀-모델별-성능-분석)
- [2. 이미지 분류 모델 비교: 손글씨 숫자 인식](#2-이미지-분류-모델-비교-손글씨-숫자-인식)
  - [데이터셋 소개](#데이터셋-소개-1)
  - [분류 모델별 성능 분석](#분류-모델별-성능-분석)
- [3. 이미지 데이터 처리와 변환](#3-이미지-데이터-처리와-변환)
  - [기본 이미지 처리 (PIL \& NumPy)](#기본-이미지-처리-pil--numpy)
  - [머신러닝을 위한 데이터 변환](#머신러닝을-위한-데이터-변환)
- [4. 프로젝트 심층 분석: 꽃 이미지 분류 시스템](#4-프로젝트-심층-분석-꽃-이미지-분류-시스템)
  - [프로젝트 개요](#프로젝트-개요)
  - [데이터 처리 파이프라인](#데이터-처리-파이프라인)
  - [모델 성능 분석 및 한계점](#모델-성능-분석-및-한계점)
    - [K값에 따른 성능 변화](#k값에-따른-성능-변화)
    - [상세 분류 리포트 (K=7 기준)](#상세-분류-리포트-k7-기준)
  - [성능 개선을 위한 제언](#성능-개선을-위한-제언)
    - [1. 데이터 증강 (Data Augmentation)](#1-데이터-증강-data-augmentation)
    - [2. 합성곱 신경망 (CNN, Convolutional Neural Network)](#2-합성곱-신경망-cnn-convolutional-neural-network)
    - [3. 전이 학습 (Transfer Learning)](#3-전이-학습-transfer-learning)
- [5. 종합 성능 비교 및 결론](#5-종합-성능-비교-및-결론)
  - [회귀 및 분류 모델 성능 요약](#회귀-및-분류-모델-성능-요약)
  - [핵심 인사이트](#핵심-인사이트)
- [6. 핵심 요약](#6-핵심-요약)
  - [과적합(Overfitting) 탐지 및 방지](#과적합overfitting-탐지-및-방지)
  - [회귀와 분류의 핵심 차이](#회귀와-분류의-핵심-차이)

---

## 1. 회귀 분석 모델 비교: 당뇨병 예측

### 데이터셋 소개

-   **데이터**: Scikit-learn의 `load_diabetes` 데이터셋
-   **샘플 수**: 442개
-   **특성 수**: 10개 (나이, 성별, BMI, 혈압 및 6가지 혈청 측정치)
-   **목표 변수**: 1년 후의 당뇨병 진행도를 나타내는 연속적인 수치
-   **특징**: 모든 독립 변수는 평균이 0, 분산이 1이 되도록 **표준화(Standardization)** 되어 있어 모델 학습에 용이합니다.

| 특성 | 설명 |
| :--- | :--- |
| `age` | 나이 |
| `sex` | 성별 |
| `bmi` | 체질량 지수 (Body Mass Index) |
| `bp` | 평균 혈압 (Blood Pressure) |
| `s1` | 혈청 총 콜레스테롤 (TC) |
| `s2` | 저밀도 지단백질 (LDL) |
| `s3` | 고밀도 지단백질 (HDL) |
| `s4` | 총 콜레스테롤 / HDL 비율 (TCH) |
| `s5` | 혈청 중성지방 로그 값 (LTG) |
| `s6` | 혈당 수치 (GLU) |

### 회귀 모델별 성능 분석

> **평가 지표**: **결정계수(R²)**. 1에 가까울수록 모델이 데이터를 잘 설명함을 의미합니다.

| 순위 | 모델명 | 하이퍼파라미터 (설정값) | 테스트셋 R² | 훈련셋 R² | 주요 특징 및 분석 |
|:---:|:---|:---:|:---:|:---:|:---|
| **1** | **Random Forest** | `n_estimators=300`, `max_depth=3`, `random_state=0` | **0.4800** | 0.5810 | 다수의 의사결정트리를 결합한 **앙상블 모델**. `n_estimators`는 트리의 개수, `max_depth`는 트리의 최대 깊이를 제한하여 과적합을 방지하고 안정적인 예측 성능을 제공합니다. |
| **2** | **Lasso (L1)** | `alpha=0.1` | **0.4752** | 0.5202 | **L1 정규화**를 통해 중요하지 않은 특성의 계수를 0으로 만들어 **자동으로 특성을 선택**하는 효과가 있습니다. `alpha`는 정규화 강도를 조절하는 하이퍼파라미터입니다. |
| **3** | **Ridge (L2)** | `alpha=0.1` | **0.4723** | 0.5225 | **L2 정규화**를 적용하여 계수들의 크기를 제한함으로써 모델의 과적합을 막고 안정성을 높입니다. `alpha`는 정규화 강도를 조절하는 하이퍼파라미터입니다. |
| **4** | **Linear Regression** | 기본 설정 | 0.4694 | 0.5304 | 가장 기본적인 선형 모델. 성능의 기준점 역할을 합니다. |
| **5** | **Gradient Boosting** | `n_estimators=10`, `max_depth=3`, `learning_rate=0.1`, `random_state=0` | 0.4397 | 0.5086 | 이전 모델의 오차를 보완하며 순차적으로 학습하는 **부스팅 계열 앙상블**. `learning_rate`는 각 트리의 기여도를 조절합니다. |
| **6** | **XGBoost** | `n_estimators=10`, `max_depth=3`, `learning_rate=0.1`, `random_state=0` | 0.4179 | 0.4964 | Gradient Boosting을 개선한 고성능 알고리즘으로, 속도와 성능 면에서 뛰어납니다. |
| **7** | **Decision Tree** | 기본 설정 | **-0.0732** | 1.0000 | 단일 의사결정트리는 훈련 데이터에 **심각하게 과적합**되어 새로운 데이터에 대한 예측 능력이 전혀 없습니다. (R²가 음수인 것은 모델이 평균값 예측보다 못하다는 의미) |

## 2. 이미지 분류 모델 비교: 손글씨 숫자 인식

### 데이터셋 소개

-   **데이터**: Scikit-learn의 `load_digits` 데이터셋
-   **샘플 수**: 1,797개
-   **이미지 크기**: 8×8 픽셀 (총 64개 특성)
-   **색상**: 흑백 (Grayscale)
-   **목표 변수**: 0부터 9까지의 숫자 분류 (10개 클래스)
-   **데이터 분할**: `train_test_split`을 사용하여 훈련 데이터 1257개, 테스트 데이터 540개로 분할 (`test_size=0.3`)

### 분류 모델별 성능 분석

> **평가 지표**: **정확도(Accuracy)**. 전체 예측 중 올바르게 예측한 비율.

| 순위 | 모델명 | 하이퍼파라미터 (설정값) | 테스트셋 정확도 | 훈련셋 정확도 | 주요 특징 및 분석 |
|:---:|:---|:---:|:---:|:---:|:---|
| **1** | **K-Nearest Neighbors (KNN)** | `n_neighbors=3` | **98.89%** | 98.89% | 주변의 K개 이웃 데이터를 보고 클래스를 결정하는 **거리 기반 모델**. `n_neighbors`는 고려할 이웃의 수를 지정합니다. 단순하지만 손글씨 같이 패턴이 명확한 데이터에서 매우 높은 성능을 보입니다. |
| **2** | **Logistic Regression** | `solver='lbfgs'`, `max_iter=5000`, `random_state=0` | 96.85% | 1.0000 | 클래스별 확률을 계산하는 **선형 분류 모델**. `solver`는 최적화 알고리즘, `max_iter`는 수렴을 위한 최대 반복 횟수를 지정합니다. 다중 분류에서는 `One-vs-Rest` 방식을 사용하며, 빠르고 해석이 용이합니다. |
| **3** | **Gradient Boosting** | `n_estimators=100`, `max_depth=4`, `learning_rate=0.1`, `random_state=0` | 95.74% | 1.0000 | 순차적 학습을 통해 분류 성능을 점진적으로 높이는 **앙상블 모델**. `learning_rate`는 각 트리의 기여도를 조절하며, `max_depth`는 트리의 최대 깊이를 제한합니다. 과적합 경향이 있으나 성능이 우수합니다. |
| **4** | **Random Forest** | `n_estimators=100`, `max_depth=4`, `random_state=0` | 93.70% | 0.9387 | **앙상블 모델**로, `n_estimators`는 트리의 개수, `max_depth`는 트리의 최대 깊이를 제한하여 과적합 위험이 적고 안정적인 성능을 제공합니다. |
| **5** | **Decision Tree** | `max_depth=5` | 67.96% | 0.6866 | 단일 의사결정트리는 복잡한 패턴을 학습하는 데 한계가 있어 상대적으로 낮은 성능을 보입니다. `max_depth`는 트리의 최대 깊이를 제한하여 과적합을 조절합니다. |

## 3. 이미지 데이터 처리와 변환

머신러닝 모델이 이미지를 학습하기 위해서는 숫자 형태의 데이터, 즉 **NumPy 배열**로 변환하는 과정이 필수적입니다.

### 기본 이미지 처리 (PIL & NumPy)

-   **이미지 로딩**: `PIL.Image.open()` 함수로 이미지를 불러옵니다.
-   **NumPy 변환**: `np.array()`를 통해 이미지를 픽셀 값으로 구성된 NumPy 배열로 변환합니다.
-   **이미지 형태(Shape)**:
    -   **컬러 이미지**: `(높이, 너비, 3)` → 3은 RGB 채널을 의미합니다.
    -   **흑백 이미지**: `(높이, 너비)` 또는 `(높이, 너비, 1)`
    -   **픽셀 값**: 각 픽셀은 0(검은색)부터 255(흰색)까지의 정수 값을 가집니다.

```python
# 예시: 이미지 파일을 불러와 NumPy 배열로 변환하기
import PIL.Image as pilimg
import numpy as np

# 1. 이미지 파일 열기
img = pilimg.open("./img/sample.jpg")

# 2. NumPy 배열로 변환
pix = np.array(img)

# 3. 이미지 형태와 픽셀 값 확인
print(f"이미지 형태(Shape): {pix.shape}")
# 출력 예시: 이미지 형태(Shape): (400, 600, 3)
```

### 머신러닝을 위한 데이터 변환

여러 장의 이미지를 일괄 처리하여 모델의 입력 데이터로 만들기 위한 과정입니다.

1.  **이미지 크기 통일 (Resize)**: 모델에 입력되는 모든 이미지의 크기(높이, 너비)가 동일해야 합니다. `img.resize((width, height))`를 사용합니다.
2.  **차원 변환 (Reshape)**: Scikit-learn과 같은 전통적인 머신러닝 모델은 2차원 데이터를 입력으로 받습니다. 따라서 3차원(컬러) 또는 4차원(여러 장의 컬러 이미지) 배열을 2차원으로 변환해야 합니다.
    -   `원본 형태`: `(이미지 개수, 높이, 너비, 채널)`
    -   `변환 후 형태`: `(이미지 개수, 높이 * 너비 * 채널)`
3.  **정규화 (Normalization)**: 픽셀 값을 0~255 범위에서 0~1 범위로 조정합니다. 이는 모델의 학습 속도를 높이고 안정성을 향상시킵니다. `X / 255.0`
4.  **라벨링 (Labeling)**: 각 이미지에 해당하는 정답(클래스)을 숫자로 부여합니다. (예: `daisy=0`, `rose=1`)
5.  **데이터 저장 (Save)**: 전처리된 이미지 데이터와 라벨을 `.npz` 파일로 저장하면, 나중에 빠르고 효율적으로 불러올 수 있습니다.

```python
# 예시: 여러 이미지를 일괄 처리하여 NPZ 파일로 저장하기
import os
import numpy as np
import PIL.Image as pilimg

path = "./img/animal"
imageList = []
labelList = []

# 폴더 내 모든 이미지 처리
for filename in os.listdir(path):
    # 1. 이미지 로딩 및 크기 통일
    img = pilimg.open(os.path.join(path, filename))
    img_resized = img.resize((80, 80))
    
    # 2. NumPy 배열로 변환
    pixel = np.array(img_resized)
    imageList.append(pixel)
    
    # 4. 라벨링 (파일 이름 기반)
    if "cat" in filename:
        labelList.append(0)
    elif "dog" in filename:
        labelList.append(1)

# 3. 차원 변환 및 정규화
X_data = np.array(imageList)
X_reshaped = X_data.reshape(len(X_data), -1) # 2차원으로 변환
X_normalized = X_reshaped / 255.0 # 정규화

# 5. NPZ 파일로 저장
np.savez("./data/animal_data.npz", data=X_normalized, labels=labelList)
```

## 4. 프로젝트 심층 분석: 꽃 이미지 분류 시스템

### 프로젝트 개요

-   **목표**: 5가지 종류의 꽃(데이지, 민들레, 장미, 해바라기, 튤립) 이미지를 자동으로 분류하는 시스템 구축
-   **데이터**: 총 4,317개의 컬러 이미지
-   **클래스별 샘플 수**: 데이지(764), 민들레(1052), 해바라기(733), 장미(784), 튤립(984)

### 데이터 처리 파이프라인

1.  **데이터 수집**: 각 꽃 종류별로 폴더를 나누어 이미지를 저장합니다.
2.  **전처리 함수 `makeData()`**: 폴더별로 이미지를 읽어 `80x80` 크기로 통일하고, NumPy 배열로 변환 후 클래스별로 라벨링하여 `.npz` 파일로 저장합니다.

    ```python
    import os
    import numpy as np
    import PIL.Image as pilimg
    import imghdr # 이미지 파일 형식 확인

    def makeData(folder, label):
        data = []
        labels = []
        # 이미지 파일이 저장된 경로
        path = "./img/flowers/" + folder
        
        # 폴더 내 모든 파일 순회
        for filename in os.listdir(path):
            # 이미지 파일인지 확인 (gif, png, jpg, jpeg 확장자만 처리)
            kind = imghdr.what(os.path.join(path, filename))
            if kind in ["gif", "png", "jpg", "jpeg"]:
                try:
                    # 이미지 열기
                    img = pilimg.open(os.path.join(path, filename))
                    # 이미지 크기 80x80으로 통일
                    resize_img = img.resize((80, 80))
                    # NumPy 배열로 변환
                    pixel = np.array(resize_img)
                    
                    # 컬러 이미지 (80, 80, 3) 형태만 처리
                    if pixel.shape == (80, 80, 3):
                        data.append(pixel)
                        labels.append(label)
                except Exception as e:
                    print(f"Error processing {filename}: {e}")
        
        # 전처리된 데이터와 라벨을 NPZ 파일로 저장
        np.savez(f"./data/{folder}.npz", data=data, targets=labels)
        print(f"{folder}.npz 파일 저장 완료. 이미지 수: {len(data)}")
    ```

3.  **데이터 통합 함수 `loadData()`**: 저장된 `.npz` 파일들을 모두 불러와 하나의 데이터셋으로 통합합니다.

    ```python
    from sklearn.model_selection import train_test_split
    import numpy as np

    def loadData():
        # 각 꽃 종류별 NPZ 파일 로드
        daisy = np.load("./data/daisy.npz")
        dandelion = np.load("./data/dandelion.npz")
        rose = np.load("./data/rose.npz")
        sunflower = np.load("./data/sunflower.npz")
        tulip = np.load("./data/tulip.npz")
        
        # 모든 데이터 통합 (이미지 데이터와 타겟 라벨)
        data = np.concatenate((daisy["data"], dandelion["data"], rose["data"], sunflower["data"], tulip["data"]))
        target = np.concatenate((daisy["targets"], dandelion["targets"], rose["targets"], sunflower["targets"], tulip["targets"]))
        
        print(f"통합된 데이터 형태: {data.shape}")
        print(f"통합된 타겟 형태: {target.shape}")
        
        return data, target
    ```

4.  **최종 전처리**: 통합된 데이터를 머신러닝 모델(KNN)에 학습시키기 위해 2차원으로 변환(`(4317, 80*80*3)`)하고 0~1 사이로 정규화합니다.
5.  **모델 학습 및 평가**: 데이터를 훈련셋과 테스트셋으로 5:5 분할하고, `KNeighborsClassifier` 모델로 학습 및 평가를 진행합니다.

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report
    import numpy as np

    # 1. 데이터 로드
    data, target = loadData()

    # 2. 차원 축소 및 정규화
    # (이미지 개수, 높이, 너비, 채널) -> (이미지 개수, 높이 * 너비 * 채널)
    data_reshaped = data.reshape(data.shape[0], -1) # -1은 나머지 차원을 자동으로 계산
    data_normalized = data_reshaped / 255.0 # 픽셀 값을 0-1 범위로 정규화

    print(f"최종 전처리된 데이터 형태: {data_normalized.shape}")

    # 3. 데이터 분할 (훈련셋 50%, 테스트셋 50%)
    X_train, X_test, y_train, y_test = train_test_split(data_normalized, target, test_size=0.5, random_state=42)

    print(f"훈련 데이터 형태: {X_train.shape}, 테스트 데이터 형태: {X_test.shape}")

    # 4. KNN 모델 학습
    # 최적의 K값인 7을 사용
    model = KNeighborsClassifier(n_neighbors=7) 
    model.fit(X_train, y_train)

    # 5. 모델 평가
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)

    print(f"훈련셋 정확도: {train_accuracy:.4f}")
    print(f"테스트셋 정확도: {test_accuracy:.4f}")

    # 상세 분류 리포트 (테스트셋 기준)
    print("\nClassification Report (Test Set):")
    print(classification_report(y_test, y_test_pred, target_names=['daisy', 'dandelion', 'sunflower', 'rose', 'tulip']))
    ```


### 모델 성능 분석 및 한계점

#### K값에 따른 성능 변화

| K값 | 테스트셋 정확도 | 분석 |
|:---:|:---|:---|
| 3 | 32.10% | K값이 너무 작아 노이즈에 민감할 수 있음 |
| 5 | 32.93% | |
| **7** | **34.09%** | **최적의 K값**. 가장 높은 정확도를 기록 |
| 9 | 34.04% | |
| 11 | 33.67% | K값이 커지면서 결정 경계가 너무 단순해져 성능 하락 |

#### 상세 분류 리포트 (K=7 기준)

| 꽃 종류 | Precision | Recall | F1-Score | 주요 문제점 |
|:---|:---:|:---:|:---:|:---|
| 데이지 | 0.18 | 0.07 | 0.10 | 모델이 데이지를 거의 맞추지 못함 (낮은 재현율) |
| **민들레** | **0.30** | **0.86** | **0.44** | **민들레로 예측하면 대부분 맞지만(높은 재현율), 다른 꽃도 민들레로 잘못 예측함(낮은 정밀도)** |
| 해바라기 | 0.54 | 0.34 | 0.42 | 해바라기라고 예측한 것 중 절반만 정답 |
| 장미 | 0.45 | 0.14 | 0.22 | 실제 장미 중 14%만 장미로 올바르게 인식 |
| 튤립 | 0.47 | 0.09 | 0.15 | 실제 튤립 중 9%만 튤립으로 올바르게 인식 |

> **결론**: 전체 정확도가 **34.09%**로 매우 낮으며, 특히 **민들레(dandelion) 클래스에 편향**된 예측을 보입니다. 이는 전통적인 머신러닝 모델이 이미지의 복잡한 시각적 특징(형태, 질감, 배경 등)을 단순 픽셀 값만으로는 학습하기 어렵다는 **명백한 한계**를 보여줍니다.

### 성능 개선을 위한 제언

단순 픽셀값 기반의 KNN 모델의 한계를 극복하고, 이미지 분류 성능을 획기적으로 높이기 위해 다음과 같은 **딥러닝(Deep Learning)** 기법 도입을 제안합니다.

#### 1. 데이터 증강 (Data Augmentation)
-   **목적**: 제한된 수의 원본 이미지에 인위적인 변형(회전, 확대/축소, 좌우 반전, 밝기 조절 등)을 가하여 훈련 데이터의 양과 다양성을 늘리는 기법입니다.
-   **효과**: 모델이 다양한 구도와 환경의 이미지를 학습하게 되어 **과적합을 방지**하고 **일반화 성능을 향상**시킵니다.

#### 2. 합성곱 신경망 (CNN, Convolutional Neural Network)
-   **개념**: 이미지의 공간적 특징(선, 면, 형태 등)을 효과적으로 추출하기 위해 설계된 딥러닝 모델입니다.
-   **핵심 구성 요소**:
    -   **합성곱 계층(Convolutional Layer)**: 필터(Filter)를 사용해 이미지의 국소적인 특징을 추출합니다.
    -   **풀링 계층(Pooling Layer)**: 특징맵의 크기를 줄여 계산 효율성을 높이고, 주요 특징만 남깁니다.
    -   **완전 연결 계층(Fully Connected Layer)**: 추출된 특징들을 기반으로 최종적인 분류를 수행합니다.
-   **장점**: KNN과 같은 모델과 달리, 픽셀의 위치 정보를 보존하며 **고차원적인 시각적 패턴을 학습**할 수 있어 이미지 인식에서 월등한 성능을 보입니다.

#### 3. 전이 학습 (Transfer Learning)
-   **개념**: 수백만 장의 대규모 이미지 데이터셋(예: ImageNet)으로 미리 훈련된 강력한 CNN 모델(예: VGG16, ResNet, EfficientNet)을 가져와, 우리의 꽃 분류 문제에 맞게 재조정하여 사용하는 방식입니다.
-   **효과**: 적은 양의 데이터로도 매우 높은 성능을 낼 수 있으며, 모델 개발 시간을 단축시키는 가장 효율적인 방법 중 하나입니다.

## 5. 종합 성능 비교 및 결론

### 회귀 및 분류 모델 성능 요약

-   **회귀 분석 (당뇨병 예측)**: **Random Forest**와 같은 **앙상블 모델**이 가장 안정적이고 높은 예측 성능을 보였습니다. 반면, 단일 **Decision Tree**는 과적합 문제로 인해 사용이 부적합했습니다.
-   **분류 분석 (손글씨 인식)**: **KNN**이 98.89%라는 매우 높은 정확도를 기록했습니다. 이는 손글씨 숫자 데이터가 비교적 단순하고 클래스 간 구분이 명확하기 때문입니다.

### 핵심 인사이트

> **"문제의 복잡도에 맞는 적절한 모델 선택이 중요하다."**

-   **단순한 문제**: 선형 모델, KNN, Decision Tree 등 간단한 모델로도 충분히 좋은 성능을 낼 수 있습니다. (예: 손글씨 숫자 인식)
-   **복잡한 문제**: 앙상블 모델이나 더 고도화된 알고리즘이 필요합니다. (예: 당뇨병 데이터)
-   **고차원 비정형 데이터 (이미지 등)**: 전통적인 머신러닝 모델로는 한계가 명확하며, **CNN과 같은 딥러NING 모델**이 필수적입니다. (예: 꽃 분류)

## 6. 핵심 요약

### 과적합(Overfitting) 탐지 및 방지

-   **과적합이란?**: 모델이 훈련 데이터에만 지나치게 최적화되어, 새로운 데이터(테스트 데이터)에 대한 예측 성능이 떨어지는 현상입니다. 이는 모델의 복잡도가 데이터의 복잡도에 비해 너무 높을 때 발생하기 쉽습니다.
-   **탐지 신호**:
    -   훈련셋 성능은 매우 높으나(예: 99~100%), 테스트셋 성능은 현저히 낮을 때.
    -   Decision Tree의 R² 값이 음수가 나오는 경우 (모델이 평균값 예측보다 못하다는 의미).
-   **방지 전략**:
    1.  **정규화 (Regularization)**: 모델의 복잡도에 페널티를 부여하여 과적합을 줄이는 기법입니다.
        -   **L1 정규화 (Lasso)**: 중요하지 않은 특성의 계수를 0으로 만들어 **특성 선택** 효과를 가집니다.
        -   **L2 정규화 (Ridge)**: 계수들의 크기를 제한하여 모델의 안정성을 높입니다.
    2.  **앙상블 (Ensemble)**: Random Forest, Gradient Boosting 등 여러 모델을 결합하여 개별 모델의 과적합 경향을 상쇄하고 안정성을 높입니다.
    3.  **하이퍼파라미터 튜닝**: 모델의 복잡도를 조절하는 매개변수(`max_depth`, `n_estimators`, `alpha`, `learning_rate` 등)를 적절히 설정하여 과적합을 방지합니다. 예를 들어, 의사결정트리의 `max_depth`를 제한하면 트리가 너무 깊어져 훈련 데이터에만 과도하게 맞춰지는 것을 막을 수 있습니다.
    4.  **데이터 확보**: 더 많은 데이터를 수집하거나 **데이터 증강(Data Augmentation)**을 활용하여 모델이 다양한 패턴을 학습하도록 돕습니다.
    5.  **교차 검증 (Cross-Validation)**: 데이터를 여러 번 나누어 평가함으로써 모델 성능의 신뢰도를 높이고, 특정 데이터셋에 대한 과적합 여부를 판단하는 데 도움을 줍니다.

### 회귀와 분류의 핵심 차이

| 구분 | **회귀 (Regression)** | **분류 (Classification)** |
|:---|:---|:---|
| **목표** | 연속적인 **수치** 예측 (예: 주가, 온도, 당뇨병 진행도) | 이산적인 **카테고리** 예측 (예: 개/고양이, 숫자 0~9, 꽃 종류) |
| **평가 지표** | R² (결정계수: 1에 가까울수록 좋음); MSE (평균 제곱 오차: 작을수록 좋음); MAE (평균 절대 오차: 작을수록 좋음) | 정확도(Accuracy); 정밀도(Precision); 재현율(Recall); F1-Score |
| **주요 모델** | Linear Regression, Ridge, Lasso, RandomForestRegressor | Logistic Regression, KNN, SVM, RandomForestClassifier |
| **결과 해석** | 예측값과 실제값의 오차 크기 | 어떤 클래스로 분류되었는지의 정확성 |

---

[⏮️ 이전 문서](./0707_ML정리.md) | [다음 문서 ⏭️](./0709_ML정리.md)