{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측: 데이터 전처리부터 모델 학습까지\n",
    "\n",
    "이 노트북은 Kaggle의 대표적인 데이터셋인 타이타닉 생존자 예측 문제를 해결하기 위한 포괄적인 머신러닝 워크플로우를 다룹니다. 데이터 로드부터 전처리(결측치, 이상치, 범주형 데이터), 그리고 모델 학습 및 평가에 이르는 전 과정을 단계별로 상세히 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns # 시각화를 위해 추가\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier # 중요도 파악을 위해 원본 스크립트에 있었음\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestClassifier # 최종 모델\n",
    "\n",
    "import os # 파일 경로 지정을 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 로드 및 초기 탐색\n",
    "\n",
    "`train.csv`와 `test.csv` 파일을 불러와 데이터의 기본적인 구조와 내용을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv(\"./data/타이타닉2/train.csv\")\n",
    "    test_df = pd.read_csv(\"./data/타이타닉2/test.csv\")\n",
    "    print(\"데이터 로드 성공!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: './data/타이타닉2/' 폴더 또는 파일이 없습니다.\")\n",
    "    print(\"노트북이 있는 폴더(02_practice/0716) 아래에 'data/타이타닉2/' 폴더를 만들고 train.csv와 test.csv를 넣어주세요.\")\n",
    "    train_df, test_df = None, None\n",
    "\n",
    "if train_df is not None:\n",
    "    print(\"\n훈련 데이터 shape:\", train_df.shape)\n",
    "    print(\"테스트 데이터 shape:\", test_df.shape)\n",
    "    print(\"\n훈련 데이터 상위 5행:\")\n",
    "    print(train_df.head())\n",
    "    print(\"\n훈련 데이터 정보:\")\n",
    "    train_df.info()\n",
    "    print(\"\n훈련 데이터 통계 요약:\")\n",
    "    print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 불필요한 열 제거\n",
    "\n",
    "`PassengerId`, `Name`, `SibSp`, `Parch`는 예측에 직접적인 도움이 되지 않거나 다른 특성으로 대체될 수 있습니다. `Cabin`은 결측치가 너무 많아 제거하는 것이 합리적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_df is not None:\n",
    "    # 원본 데이터프레임을 직접 수정하지 않기 위해 복사본을 만듭니다.\n",
    "    train_df_processed = train_df.copy()\n",
    "    test_df_processed = test_df.copy()\n",
    "\n",
    "    drop_columns = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Cabin']\n",
    "    train_df_processed = train_df_processed.drop(columns=drop_columns)\n",
    "    test_df_processed = test_df_processed.drop(columns=drop_columns)\n",
    "\n",
    "    print(\"\n열 제거 후 훈련 데이터 상위 5행:\")\n",
    "    print(train_df_processed.head())\n",
    "    print(\"열 제거 후 훈련 데이터 shape:\", train_df_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 결측치 처리\n",
    "\n",
    "`Age`와 `Embarked` 열에 결측치가 존재합니다. `Age`는 평균값으로 대체하고, `Embarked`는 결측치가 적으므로 해당 행을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_df_processed is not None:\n",
    "    print(\"\n결측치 확인 (처리 전):\")\n",
    "    print(train_df_processed.isna().sum())\n",
    "\n",
    "    # Age 결측치 평균으로 대체\n",
    "    age_mean = train_df_processed[\"Age\"].mean() \n",
    "    train_df_processed['Age'].fillna(age_mean, inplace=True) \n",
    "    test_df_processed['Age'].fillna(age_mean, inplace=True)\n",
    "\n",
    "    # Embarked 결측치 행 제거\n",
    "    train_df_processed = train_df_processed.dropna(axis=0, how='any') \n",
    "    # 테스트 데이터셋의 Embarked 결측치도 처리 (원본 스크립트와 동일하게 행 제거)\n",
    "    test_df_processed = test_df_processed.dropna(axis=0, how='any')\n",
    "\n",
    "    print(\"\n결측치 확인 (처리 후):\")\n",
    "    print(train_df_processed.isna().sum())\n",
    "    print(test_df_processed.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 이상치 처리 (IQR 방식)\n",
    "\n",
    "`Fare`와 `Age` 열에 이상치가 있을 수 있습니다. IQR(사분위수 범위) 방식을 사용하여 이상치를 탐지하고, 해당 값을 상한/하한 경계값으로 대체(capping)합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outfliers_iqr(data_series):\n",
    "    q1, q3 = np.percentile(data_series, [25, 75])  \n",
    "    iqr = q3 - q1 \n",
    "    lower_bound = q1 - iqr * 1.5\n",
    "    upper_bound = q3 + iqr * 1.5\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "if train_df_processed is not None:\n",
    "    for col in ['Fare', 'Age']:\n",
    "        lower, upper = outfliers_iqr(train_df_processed[col])\n",
    "        train_df_processed[col][train_df_processed[col] < lower] = lower \n",
    "        train_df_processed[col][train_df_processed[col] > upper] = upper \n",
    "\n",
    "        lower_test, upper_test = outfliers_iqr(test_df_processed[col])\n",
    "        test_df_processed[col][test_df_processed[col] < lower_test] = lower_test \n",
    "        test_df_processed[col][test_df_processed[col] > upper_test] = upper_test \n",
    "\n",
    "    # 이상치 처리 후 boxplot (주석 해제하여 확인 가능)\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # train_df_processed['Fare'].plot(kind='box', title='Fare after Outlier Treatment')\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # train_df_processed['Age'].plot(kind='box', title='Age after Outlier Treatment')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 범주형 데이터 원-핫 인코딩\n",
    "\n",
    "`Sex`와 `Embarked`는 범주형 데이터이므로, 머신러닝 모델이 이해할 수 있도록 원-핫 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_df_processed is not None:\n",
    "    train_df_encoded = pd.get_dummies(train_df_processed)\n",
    "    test_df_encoded = pd.get_dummies(test_df_processed)\n",
    "\n",
    "    print(\"\n원-핫 인코딩 후 훈련 데이터 상위 5행:\")\n",
    "    print(train_df_encoded.head())\n",
    "    print(\"원-핫 인코딩 후 훈련 데이터 컬럼:\")\n",
    "    print(train_df_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 특성(X)과 타겟(y) 분리\n",
    "\n",
    "훈련 데이터에서 예측 대상인 `Survived` 열을 타겟(`y`)으로, 나머지 열을 특성(`X`)으로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_df_encoded is not None:\n",
    "    X_train = train_df_encoded.drop(columns=['Survived'])\n",
    "    y_train = train_df_encoded['Survived']\n",
    "\n",
    "    # 테스트 데이터셋은 Survived 컬럼이 없으므로 그대로 사용\n",
    "    X_test = test_df_encoded\n",
    "\n",
    "    print(\"\n훈련 특성 데이터 shape:\", X_train.shape)\n",
    "    print(\"훈련 타겟 데이터 shape:\", y_train.shape)\n",
    "    print(\"테스트 특성 데이터 shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 학습 및 평가 (RandomForestClassifier)\n",
    "\n",
    "전처리된 데이터를 사용하여 `RandomForestClassifier` 모델을 학습시키고, 훈련 데이터에 대한 정확도를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0) # 재현성을 위해 random_state 추가\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    print(f\"훈련 세트 정확도: {train_score:.4f}\")\n",
    "\n",
    "    # 테스트 데이터에 대한 예측 (실제 Kaggle 제출 시 사용)\n",
    "    # test_pred = model.predict(X_test)\n",
    "    # print(\"테스트 데이터 예측 (일부):\", test_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. (선택 사항) 상관관계 분석\n",
    "\n",
    "특성 간의 상관관계를 히트맵으로 시각화하여 데이터의 구조를 파악할 수 있습니다. 특성의 개수가 많을 경우 `pairplot`은 비효율적이므로, 상관관계 히트맵이 더 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_df_encoded is not None:\n",
    "    correlation_matrix = train_df_encoded.corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True, \n",
    "                cmap='coolwarm', \n",
    "                fmt='.2f', \n",
    "                linewidths=.5 \n",
    "               )\n",
    "    plt.xticks(rotation=45, ha='right') \n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title('타이타닉 데이터셋 특성 간 상관관계 히트맵')\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}