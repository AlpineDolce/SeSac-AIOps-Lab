{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 손글씨 숫자 분류: 딥러닝 첫걸음\n",
    "\n",
    "이 노트북은 가장 대표적인 딥러닝 예제인 MNIST 손글씨 숫자 데이터셋을 사용하여, 기본적인 완전 연결 신경망(Dense Neural Network)을 구축하고 훈련시키는 전체 과정을 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 임포트 및 환경 설정\n",
    "필요한 라이브러리를 불러오고, 재현성을 위해 텐서플로우의 랜덤 시드를 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import models, layers\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 로드 및 확인\n",
    "Keras에 내장된 MNIST 데이터셋을 로드하고, 훈련 데이터와 테스트 데이터의 형태(shape)를 출력하여 구조를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 훈련 데이터 ---\n",
      "이미지 형태: (60000, 28, 28)\n",
      "레이블 형태: (60000,)\n",
      "--- 테스트 데이터 ---\n",
      "이미지 형태: (10000, 28, 28)\n",
      "레이블 형태: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"--- 훈련 데이터 ---\")\n",
    "print(\"이미지 형태:\", train_images.shape)\n",
    "print(\"레이블 형태:\", train_labels.shape)\n",
    "\n",
    "print(\"--- 테스트 데이터 ---\")\n",
    "print(\"이미지 형태:\", test_images.shape)\n",
    "print(\"레이블 형태:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리\n",
    "신경망에 데이터를 입력하기 전에 두 가지 주요 전처리 작업을 수행합니다.\n",
    "\n",
    "1.  **차원 변환 (Reshaping)**: 2차원 이미지 데이터(28x28 픽셀)를 1차원 벡터(784)로 펼칩니다. 이는 `Dense` 레이어에 입력하기 위함입니다.\n",
    "2.  **정규화 (Normalization/Scaling)**: 픽셀 값의 범위를 0-255에서 0-1 사이로 조정합니다. 이는 모델의 학습을 더 안정적이고 빠르게 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 훈련 이미지 형태: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 이미지 전처리\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], 28 * 28)\n",
    "train_images_scaled = train_images_flat.astype('float32') / 255\n",
    "\n",
    "# 테스트 이미지 전처리\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], 28 * 28)\n",
    "test_images_scaled = test_images_flat.astype('float32') / 255\n",
    "\n",
    "print(\"전처리 후 훈련 이미지 형태:\", train_images_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 신경망 모델 구축\n",
    "`keras.Sequential`을 사용하여 모델을 순차적으로 구성합니다.\n",
    "\n",
    "- **은닉층 (Hidden Layers)**: `relu` 활성화 함수를 사용하는 여러 개의 `Dense` 층을 추가합니다.\n",
    "- **출력층 (Output Layer)**: 0부터 9까지 10개의 숫자를 분류해야 하므로, 10개의 뉴런을 가진 `Dense` 층을 사용합니다. 각 뉴런이 해당 숫자의 확률을 나타내도록 `softmax` 활성화 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\aiops\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    # 입력 데이터의 형태는 첫 번째 레이어에서 자동으로 추론됩니다.\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    # 출력층: 10개의 클래스에 대한 확률을 출력\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 컴파일\n",
    "모델을 훈련하기 전에 학습 프로세스를 설정합니다.\n",
    "\n",
    "- **Optimizer**: `rmsprop` 최적화 알고리즘을 사용합니다.\n",
    "- **Loss Function**: `sparse_categorical_crossentropy`를 손실 함수로 사용합니다. 이 함수는 레이블이 정수 형태일 때 별도의 원-핫 인코딩 없이 사용할 수 있어 편리합니다.\n",
    "- **Metrics**: 훈련 및 평가 과정에서 `accuracy`(정확도)를 모니터링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\aiops\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 훈련\n",
    "`fit()` 메서드를 사용하여 모델을 훈련시킵니다.\n",
    "\n",
    "- `epochs`: 전체 훈련 데이터셋을 몇 번 반복하여 학습할지 결정합니다.\n",
    "- `batch_size`: 한 번에 메모리에 올릴 데이터의 양을 지정합니다. 이 배치 단위로 가중치 업데이트가 일어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\aiops\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\aiops\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3336 - accuracy: 0.8975 - val_loss: 0.1389 - val_accuracy: 0.9572\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1172 - accuracy: 0.9635 - val_loss: 0.1164 - val_accuracy: 0.9657\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9757 - val_loss: 0.1001 - val_accuracy: 0.9707\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.0910 - val_accuracy: 0.9734\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0899 - val_accuracy: 0.9750\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.1061 - val_accuracy: 0.9727\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.1075 - val_accuracy: 0.9762\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.1142 - val_accuracy: 0.9773\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.1567 - val_accuracy: 0.9693\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.1265 - val_accuracy: 0.9757\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1293 - val_accuracy: 0.9783\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.1430 - val_accuracy: 0.9747\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9769\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1534 - val_accuracy: 0.9747\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1389 - val_accuracy: 0.9793\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1596 - val_accuracy: 0.9791\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1840 - val_accuracy: 0.9757\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1857 - val_accuracy: 0.9761\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1642 - val_accuracy: 0.9777\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1577 - val_accuracy: 0.9779\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1958 - val_accuracy: 0.9762\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1604 - val_accuracy: 0.9783\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1840 - val_accuracy: 0.9758\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1721 - val_accuracy: 0.9778\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1853 - val_accuracy: 0.9779\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1771 - val_accuracy: 0.9804\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1893 - val_accuracy: 0.9791\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1926 - val_accuracy: 0.9800\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2002 - val_accuracy: 0.9793\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1890 - val_accuracy: 0.9790\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.2034 - val_accuracy: 0.9782\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.2069 - val_accuracy: 0.9760\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1708 - val_accuracy: 0.9812\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1859 - val_accuracy: 0.9803\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2173 - val_accuracy: 0.9758\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1976 - val_accuracy: 0.9788\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.5316e-04 - accuracy: 0.9998 - val_loss: 0.1930 - val_accuracy: 0.9806\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.5068e-04 - accuracy: 0.9998 - val_loss: 0.1954 - val_accuracy: 0.9816\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1983 - val_accuracy: 0.9800\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.2138 - val_accuracy: 0.9797\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2188 - val_accuracy: 0.9786\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2064 - val_accuracy: 0.9802\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2538 - val_accuracy: 0.9778\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2307 - val_accuracy: 0.9793\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.2273 - val_accuracy: 0.9779\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2654 - val_accuracy: 0.9763\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0551e-04 - accuracy: 0.9997 - val_loss: 0.2240 - val_accuracy: 0.9808\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2454 - val_accuracy: 0.9785\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.3429e-04 - accuracy: 0.9998 - val_loss: 0.2204 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 6.9790e-04 - accuracy: 0.9998 - val_loss: 0.2643 - val_accuracy: 0.9768\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2515 - val_accuracy: 0.9782\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2246 - val_accuracy: 0.9798\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.2004e-04 - accuracy: 0.9999 - val_loss: 0.2388 - val_accuracy: 0.9793\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.8808e-04 - accuracy: 0.9998 - val_loss: 0.2377 - val_accuracy: 0.9800\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6718e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9813\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3151e-06 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9818\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.3510e-07 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9818\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.7593e-07 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9818\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4243e-07 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9817\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1970e-07 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9817\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0277e-07 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9817\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8936e-07 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9818\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7845e-07 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9817\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6931e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9817\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6148e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9817\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5458e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4851e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4302e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3809e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3358e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9816\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2947e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2567e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2209e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1883e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9816\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1572e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1288e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9817\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1024e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9818\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0773e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9818\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0535e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9818\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0317e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9817\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0106e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9817\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.9048e-08 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9817\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 9.7153e-08 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9817\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 9.5355e-08 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9817\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.3612e-08 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9817\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 9.1938e-08 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9817\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.0396e-08 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9817\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 8.8841e-08 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9818\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 8.7406e-08 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9818\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6055e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9818\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 8.4672e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9818\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.3378e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9818\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.2121e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9818\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 8.0937e-08 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9818\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9777e-08 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9818\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 7.8674e-08 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9818\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 7.7562e-08 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9818\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 7.6528e-08 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9818\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 7.5567e-08 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images_scaled,  # 전처리된 훈련 이미지\n",
    "    train_labels,         # 훈련 레이블\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2  # 훈련 데이터의 20%를 검증용으로 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가\n",
    "`evaluate()` 메서드를 사용하여 훈련된 모델의 성능을 훈련 데이터셋과 테스트 데이터셋에 대해 각각 평가하고, 최종 손실(loss)과 정확도(accuracy)를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 모델 평가 ---\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0458 - accuracy: 0.9963\n",
      "훈련셋 손실: 0.0458, 정확도: 0.9963\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.9830\n",
      "테스트셋 손실: 0.1825, 정확도: 0.9830\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 모델 평가 ---\")\n",
    "train_loss, train_acc = model.evaluate(train_images_scaled, train_labels)\n",
    "print(f\"훈련셋 손실: {train_loss:.4f}, 정확도: {train_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images_scaled, test_labels)\n",
    "print(f\"테스트셋 손실: {test_loss:.4f}, 정확도: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 구조 확인\n",
    "`summary()` 메서드를 통해 모델의 전체 구조와 각 층의 파라미터 수를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308554 (1.18 MB)\n",
      "Trainable params: 308554 (1.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
