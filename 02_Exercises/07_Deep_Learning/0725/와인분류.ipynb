{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 와인 종류 분류: 딥러닝을 이용한 다중 클래스 분류\n",
    "\n",
    "이 노트북은 Scikit-learn에 내장된 와인 데이터셋을 사용하여 세 가지 종류의 와인을 분류하는 딥러닝 모델을 구축합니다. 다중 클래스 분류 문제에 딥러닝을 적용하는 전체 과정을 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 로드 및 분할\n",
    "Scikit-learn의 `load_wine` 함수를 사용하여 데이터를 로드하고, Pandas DataFrame으로 변환하여 내용을 확인합니다. 그 후, 데이터를 훈련 세트와 테스트 세트로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"데이터를 로드하고 훈련/테스트 세트로 분할합니다.\"\"\"\n",
    "    wine = load_wine()\n",
    "    X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "    y = wine.target # 0, 1, 2 세 종류의 클래스\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=123,\n",
    "        stratify=y\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "print(\"--- 데이터 확인 ---\")\n",
    "print(\"훈련 데이터 형태:\", X_train.shape)\n",
    "print(\"테스트 데이터 형태:\", X_test.shape)\n",
    "print(\"\\n고유 레이블:\", np.unique(y_train))\n",
    "print(\"\\n첫 5개 훈련 데이터 샘플:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리\n",
    "딥러닝 모델에 데이터를 입력하기 전에 두 가지 전처리 작업을 수행합니다.\n",
    "\n",
    "1.  **특성 스케일링**: `StandardScaler`를 사용하여 모든 입력 특성을 표준화합니다.\n",
    "2.  **레이블 인코딩**: `categorical_crossentropy` 손실 함수를 사용하기 위해, 정수 형태의 레이블(0, 1, 2)을 원-핫 벡터로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 원-핫 인코딩\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "print(\"--- 전처리 후 데이터 확인 ---\")\n",
    "print(\"스케일링된 훈련 데이터 형태:\", X_train_scaled.shape)\n",
    "print(\"원-핫 인코딩된 훈련 레이블 형태:\", y_train_encoded.shape)\n",
    "print(\"\\n첫 번째 원-핫 인코딩된 레이블 (원본: {}):\\n{}\".format(y_train[0], y_train_encoded[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 모델 구축\n",
    "다중 클래스 분류를 위한 `Sequential` 모델을 정의합니다.\n",
    "\n",
    "- **은닉층**: `relu` 활성화 함수를 사용하는 여러 개의 `Dense` 층으로 구성됩니다.\n",
    "- **출력층**: 3개의 와인 종류를 분류해야 하므로, 3개의 뉴런과 `softmax` 활성화 함수를 사용합니다. Softmax 함수는 각 클래스에 대한 확률 분포를 출력합니다.\n",
    "\n",
    "모델 컴파일 시:\n",
    "- **Optimizer**: `rmsprop`\n",
    "- **Loss Function**: 다중 클래스 분류 문제이고 레이블이 원-핫 인코딩되었으므로 `categorical_crossentropy`를 사용합니다.\n",
    "- **Metrics**: `accuracy`를 사용하여 모델 성능을 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 훈련\n",
    "모델을 훈련시키면서 `ModelCheckpoint` 콜백을 사용하여 검증 손실(`val_loss`)이 가장 낮은 최적의 모델을 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='와인분류_최적모델.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss'\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train_encoded, \n",
    "                    epochs=50, # 에포크 수를 늘려 충분히 학습\n",
    "                    validation_data=(X_test_scaled, y_test_encoded),\n",
    "                    callbacks=callbacks, \n",
    "                    batch_size=32, # 배치 사이즈 조정\n",
    "                    verbose=1)\n",
    "\n",
    "# 훈련 과정 기록을 pickle로 저장\n",
    "with open(\"와인분류_훈련기록.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 훈련 과정 시각화\n",
    "훈련 및 검증 과정에서의 손실과 정확도 변화를 그래프로 그려, 모델의 학습 상태를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가\n",
    "저장된 최적의 모델을 불러와 테스트 데이터셋에 대한 최종 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('와인분류_최적모델.keras')\n",
    "\n",
    "print(\"--- 최종 모델 평가 (최적 모델) ---\")\n",
    "train_loss, train_acc = best_model.evaluate(X_train_scaled, y_train_encoded)\n",
    "test_loss, test_acc = best_model.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "print(f\"훈련셋 손실값: {train_loss:.4f}, 정확도: {train_acc:.4f}\")\n",
    "print(f\"테스트셋 손실값: {test_loss:.4f}, 정확도: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}