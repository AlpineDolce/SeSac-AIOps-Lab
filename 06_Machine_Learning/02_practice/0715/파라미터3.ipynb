{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna를 활용한 하이퍼파라미터 최적화 노트북\n",
    "\n",
    "이 Jupyter Notebook은 `scikit-learn`의 유방암 데이터셋(`load_breast_cancer`)을 사용하여 **Optuna** 라이브러리를 통해 `RandomForestClassifier` 모델의 최적 하이퍼파라미터를 탐색하는 과정을 보여줍니다.\n",
    "\n",
    "**Optuna 개요:**\n",
    "* **자동화된 하이퍼파라미터 최적화**: 모델의 성능을 최대화하는 최적의 하이퍼파라미터 조합을 효율적으로 찾아줍니다.\n",
    "* **유연성**: 다양한 머신러닝 모델과 사용자 정의 목적 함수에 적용할 수 있습니다.\n",
    "* **시각화**: 최적화 과정을 시각적으로 분석할 수 있는 도구를 제공합니다.\n",
    "* **병렬 처리**: 여러 스터디를 병렬로 실행하여 최적화 시간을 단축할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## 1. 라이브러리 임포트\n",
    "\n",
    "필요한 라이브러리들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC # 하이퍼파라미터 개수가 많아서 선택함\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# classification_report: 분류 중에서도 이진 분류 평가 라이브러리\n",
    "# accuracy_score: 단순히 정확도 판단 기준\n",
    "# GridSearchCV: 파라미터를 주면 각 파라미터별로 전체 조합을 만들어서 다 돌려본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## 2. 데이터 로드 및 전처리\n",
    "\n",
    "`load_breast_cancer` 데이터셋을 로드하고, 타겟 레이블을 반전하여 0을 양성(benign), 1을 악성(malignant)으로 설정합니다. 데이터의 특성 개수, 샘플 개수, 클래스 분포를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_breast_cancer()\n",
    "# iris.data, iris.target => 데이터프레임으로\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target # 0이 악성, 1이 양성 => 둘의 값을 반전하자. 나중에 모델 평가 해석시에 그게 더 편함\n",
    "y_change = np.where(y==0, 1, 0) # 0->1 로 1->0으로 바꿈\n",
    "\n",
    "print(\"유방암 데이터셋 정보:\")\n",
    "print(f\"특성 개수 {X.shape[1]}\")\n",
    "print(f\"샘플 개수 {X.shape[0]}\")\n",
    "print(f\"클래스 분포 (0:양성 1:악성) {dict(zip(*np.unique(y_change, return_counts=True) ))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## 3. 데이터 분할\n",
    "\n",
    "데이터 불균형을 고려하여 `stratify` 옵션을 사용하여 훈련 세트와 테스트 세트를 분할합니다. 이는 각 클래스의 비율이 훈련 세트와 테스트 세트에서 동일하게 유지되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 악성인 사람과 양성인 사람 간의 데이터 불균형, iris는 균형 데이터 33:33:33\n",
    "# 불균형 데이터셋일 경우에 훈련셋과 테스트셋을 쪼갤 때 그 균형을 유지하면서 쪼개라\n",
    "# stratify=y_change\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_change, random_state=1234,\n",
    "                                                    test_size=0.2, stratify=y_change)\n",
    "print(\"훈련 데이터셋:\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(f\"y_train 분포: {dict(zip(*np.unique(y_train, return_counts=True) ))}\")\n",
    "print(f\"y_test 분포: {dict(zip(*np.unique(y_test, return_counts=True) ))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## 4. Optuna 목적 함수 정의\n",
    "\n",
    "Optuna가 최적화할 목적 함수(`objective`)를 정의합니다. 이 함수는 Optuna가 탐색할 하이퍼파라미터의 범위를 설정하고, 해당 하이퍼파라미터로 `RandomForestClassifier` 모델을 학습시킨 후 테스트 세트에서의 정확도를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial): # 변수명은 마음대로\n",
    "    # 옵투나를 통해 탐색할 하이퍼파라미터 범위를 정의한다\n",
    "    \n",
    "    max_depth = trial.suggest_int('max_depth', 5, 20) # 그리드서치 5,6,7,8,9,...20 => 시작, 엔딩\n",
    "    # 트리의 최대 깊이\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    # 리프 노드가 되기 위한 최소 샘플 수\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 100)\n",
    "\n",
    "    model = RandomForestClassifier(max_depth=max_depth,\n",
    "                                 min_samples_leaf=min_samples_leaf,\n",
    "                                 min_samples_split=min_samples_split,\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 random_state=42,\n",
    "                                 n_jobs=-1) # 내부 프로세스 CPU 개수 *2라서 -1을 주면 알아서 최대치를 사용한다\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred) # 예측 정확도\n",
    "    return accuracy # 반드시 마지막에 리턴해야 한다. 목적값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## 5. Optuna 스터디 실행\n",
    "\n",
    "Optuna 스터디를 생성하고 `objective` 함수를 호출하여 하이퍼파라미터 최적화를 수행합니다. `direction=\"maximize\"`는 정확도를 최대화하는 방향으로 최적화를 진행함을 의미합니다. `n_trials`는 시도할 횟수를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵투나 스터디 생성\n",
    "study = optuna.create_study(direction=\"maximize\") # 이익을 최대화하는 방향으로 study 객체를 만든다\n",
    "print(\"옵투나 최적화 시작 (50회 시도)\")\n",
    "study.optimize(objective, n_trials=50) # 콜백 함수, 횟수를 지정한다\n",
    "# optimize - 최적화 함수\n",
    "\n",
    "print(f\"최고 정확도: {study.best_trial.value}\")\n",
    "print(f\"최적 하이퍼파라미터: {study.best_trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
