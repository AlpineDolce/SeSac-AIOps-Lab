{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 프로젝트 워크플로우 가이드\n",
    "\n",
    "이 노트북은 일반적인 머신러닝 프로젝트의 전체 처리 순서와 각 단계에서 고려해야 할 핵심 개념들을 정리한 가이드입니다. 기초 통계부터 데이터 전처리, 모델링, 평가에 이르기까지의 과정을 체계적으로 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기초 통계: 데이터 이해의 시작\n",
    "\n",
    "머신러닝에 앞서 데이터의 특성을 파악하는 것은 매우 중요합니다. 기초 통계는 데이터 집단의 성격을 요약하고 이해하는 데 도움을 줍니다.\n",
    "\n",
    "### 1.1. 기술 통계 (Descriptive Statistics)\n",
    "데이터의 중심 경향성과 퍼진 정도를 파악합니다.\n",
    "\n",
    "- **평균 (Mean)**: 모든 데이터의 합을 개수로 나눈 값. 데이터의 중심을 나타내는 대표적인 지표지만, 이상치(outlier)에 민감하게 반응합니다.\n",
    "- **중앙값 (Median)**: 데이터를 크기순으로 정렬했을 때 중앙에 위치하는 값. 이상치의 영향을 덜 받기 때문에 데이터 분포가 한쪽으로 치우쳤을 때 평균을 보완하는 대표값으로 사용됩니다.\n",
    "- **최빈값 (Mode)**: 데이터에서 가장 빈번하게 나타나는 값. 주로 범주형 데이터의 대표값으로 사용됩니다.\n",
    "- **분산 (Variance)**: 데이터가 평균으로부터 얼마나 퍼져 있는지를 나타내는 지표. 편차(값-평균) 제곱의 평균으로 계산하며, 값이 클수록 데이터가 넓게 흩어져 있음을 의미합니다.\n",
    "- **표준편차 (Standard Deviation)**: 분산에 제곱근을 취한 값. 분산과 동일하게 데이터의 퍼진 정도를 나타내지만, 원래 데이터와 단위가 같아 해석이 더 직관적입니다.\n",
    "\n",
    "> **예시**: 두 학생의 성적\n",
    "> - 학생 A: 평균 60점, 표준편차 20점 -> 성적이 40점 ~ 80점 사이에 넓게 분포 (기복이 심함)\n",
    "> - 학생 B: 평균 70점, 표준편차 5점 -> 성적이 65점 ~ 75점 사이에 좁게 분포 (성적이 고름)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 추론 통계 (Inferential Statistics)\n",
    "\n",
    "수집된 데이터(표본)를 바탕으로 더 큰 집단(모집단)의 특성을 예측하고 추론하는 과정입니다. 머신러닝과 딥러닝은 데이터를 기반으로 미래를 예측하므로 추론 통계의 한 분야로 볼 수 있습니다.\n",
    "\n",
    "- **가설 검정**: 귀무가설(기존의 주장)과 대립가설(새로운 주장)을 설정하고, 통계적 근거를 통해 어떤 가설을 채택할지 결정합니다.\n",
    "  - **귀무가설 (H0)**: 현재까지 사실로 받아들여지는 가설 (예: 대한민국 남성의 평균 키는 173cm이다.)\n",
    "  - **대립가설 (H1)**: 귀무가설에 대립하는 새로운 주장 (예: 대한민국 남성의 평균 키는 173cm가 아니다.)\n",
    "- **유의수준 (p-value)**: 귀무가설이 맞다고 가정할 때, 현재와 같은 결과가 관측될 확률. 보통 0.05 미만일 경우 '통계적으로 유의미한 차이가 있다'고 판단하고 대립가설을 채택합니다.\n",
    "  - **T-test**: 두 그룹 간의 평균 비교 (연속형 데이터)\n",
    "  - **카이제곱 검정 (Chi-squared test)**: 두 그룹 간의 비율/빈도 비교 (범주형 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 머신러닝 프로젝트 주요 단계\n",
    "\n",
    "머신러닝은 크게 지도학습, 비지도학습, 강화학습으로 나뉩니다.\n",
    "- **지도학습 (Supervised Learning)**: 정답(label, target)이 있는 데이터를 사용하여 모델을 학습시킵니다. (회귀, 분류)\n",
    "- **비지도학습 (Unsupervised Learning)**: 정답이 없는 데이터를 사용하여 데이터의 숨겨진 구조나 패턴을 찾습니다. (군집화, 차원 축소)\n",
    "- **강화학습 (Reinforcement Learning)**: 보상(reward)을 최대화하는 방향으로 에이전트가 행동을 학습합니다. (알파고, 게임 AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 1: 문제 정의 (회귀 vs. 분류)\n",
    "\n",
    "가장 먼저 해결하고자 하는 문제가 무엇인지 명확히 해야 합니다.\n",
    "\n",
    "- **회귀 (Regression)**: 연속적인 숫자 값을 예측하는 문제. (예: 집값 예측, 주가 예측, 시험 성적 예측)\n",
    "- **분류 (Classification)**: 주어진 데이터가 어떤 범주(클래스)에 속하는지 예측하는 문제.\n",
    "  - **이진 분류 (Binary Classification)**: 두 개의 클래스 중 하나로 예측. (예: 합격/불합격, 스팸/정상 메일)\n",
    "  - **다중 분류 (Multi-class Classification)**: 세 개 이상의 클래스 중 하나로 예측. (예: 붓꽃 품종 분류, 이미지 카테고리 분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 2: 데이터 전처리 (Data Preprocessing)\n",
    "\n",
    "'Garbage in, Garbage out'이라는 말처럼, 모델의 성능은 데이터의 품질에 크게 좌우됩니다. 이 단계는 모델링에서 가장 많은 시간이 소요될 수 있습니다.\n",
    "\n",
    "1.  **결측치(Missing Value) 처리**: 비어있는 값을 어떻게 처리할지 결정합니다.\n",
    "    - **제거**: 결측치가 포함된 행이나 열을 삭제. (데이터 손실이 큼)\n",
    "    - **대체 (Imputation)**: 다른 값으로 채웁니다.\n",
    "      - 연속형 데이터: 평균(mean), 중앙값(median)으로 대체.\n",
    "      - 범주형 데이터: 최빈값(mode)으로 대체.\n",
    "\n",
    "2.  **이상치(Outlier) 제거**: 다른 데이터와 극단적으로 다른 값을 처리합니다. Boxplot 시각화나 IQR(사분위수 범위) 방법을 사용하여 탐지하고 제거하거나 수정할 수 있습니다.\n",
    "\n",
    "3.  **중복값(Duplicate) 제거**: 동일한 데이터가 중복으로 존재하는 경우 제거합니다.\n",
    "\n",
    "4.  **잘못된 값 처리**: `value_counts()`나 `unique()` 함수로 데이터의 종류를 확인하고, 논리적으로 맞지 않는 값을 수정하거나 제거합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 3: 특성 공학 (Feature Engineering)\n",
    "\n",
    "모델이 더 잘 학습할 수 있도록 데이터를 가공하고 새로운 특성을 만드는 과정입니다.\n",
    "\n",
    "1.  **범주형 데이터 인코딩**: 문자열 데이터를 숫자형으로 변환합니다.\n",
    "    - **라벨 인코딩 (Label Encoding)**: 각 범주를 고유한 숫자로 변환 (예: `male`=0, `female`=1). 범주의 개수가 적고 순서의 의미가 있을 때(Ordinal) 사용합니다. 범주가 많은데 순서 의미가 없는 데이터(Nominal)에 사용하면 모델이 숫자의 크고 작음에 영향을 받아 성능이 왜곡될 수 있습니다.\n",
    "    - **원-핫 인코딩 (One-Hot Encoding)**: 각 범주를 새로운 컬럼으로 만들고, 해당하면 1, 아니면 0으로 표시합니다. 순서 없는 범주형 데이터에 주로 사용되며, 모델의 성능 왜곡을 방지합니다.\n",
    "\n",
    "2.  **스케일링 (Feature Scaling)**: 각 특성의 값 범위를 일정한 수준으로 맞추는 작업입니다. 특성 간의 단위 차이가 클 때, 특정 특성이 모델에 과도한 영향을 미치는 것을 방지합니다. **서포트 벡터 머신(SVM), 딥러닝**과 같이 거리를 기반으로 하는 알고리즘에 특히 중요합니다.\n",
    "    - **표준화 (Standardization)**: 평균 0, 표준편차 1인 분포로 변환.\n",
    "    - **정규화 (Normalization)**: 값을 0과 1 사이의 범위로 변환."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 4: 모델 학습 및 하이퍼파라미터 튜닝\n",
    "\n",
    "- 전처리된 데이터를 사용하여 다양한 머신러닝 모델을 학습시킵니다.\n",
    "- `GridSearchCV` 등을 사용하여 모델의 성능을 최적화하는 하이퍼파라미터를 찾습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계 5: 모델 평가 (Evaluation)\n",
    "\n",
    "학습된 모델이 얼마나 좋은 성능을 내는지 객관적인 지표로 평가합니다. 평가지표는 문제의 종류(회귀/분류)에 따라 다릅니다.\n",
    "\n",
    "#### 5.1. 회귀 평가지표\n",
    "- **MAE (Mean Absolute Error)**: |실제값 - 예측값| 의 평균. 오차의 크기를 직관적으로 파악할 수 있으며 이상치에 덜 민감합니다.\n",
    "- **MSE (Mean Squared Error)**: (실제값 - 예측값)² 의 평균. 오차가 큰 값에 패널티를 부여하며, 딥러닝에서 손실 함수로 자주 사용됩니다.\n",
    "- **RMSE (Root Mean Squared Error)**: MSE에 제곱근을 취한 값. MSE와 달리 원래 데이터와 단위가 같아 해석이 용이합니다.\n",
    "- **R² (결정 계수)**: 모델이 데이터를 얼마나 잘 설명하는지를 나타냅니다. 1에 가까울수록 좋으며, `scikit-learn` 회귀 모델의 `score()` 함수가 이 값을 반환합니다. 음수가 나오면 모델이 평균으로 예측하는 것보다도 성능이 나쁘다는 의미입니다.\n",
    "\n",
    "#### 5.2. 분류 평가지표\n",
    "분류 문제, 특히 **데이터 불균형(imbalance)**이 심한 경우(예: 암환자 진단, 사기 탐지)에는 단순 정확도만으로 모델을 평가하기 어렵습니다.\n",
    "\n",
    "- **오차 행렬 (Confusion Matrix)**: 모델의 예측 결과를 실제 값과 비교하여 표로 나타낸 것입니다.\n",
    "| | 예측: Positive | 예측: Negative |\n",
    "|---|---|---|\n",
    "| **실제: Positive** | TP (True Positive) | FN (False Negative) |\n",
    "| **실제: Negative** | FP (False Positive) | TN (True Negative) |\n",
    "  - **TP**: 실제 Positive를 Positive로 올바르게 예측.\n",
    "  - **TN**: 실제 Negative를 Negative로 올바르게 예측.\n",
    "  - **FP**: 실제 Negative를 Positive로 잘못 예측 (Type I Error).\n",
    "  - **FN**: 실제 Positive를 Negative로 잘못 예측 (Type II Error, **가장 치명적인 오류인 경우가 많음**).\n",
    "\n",
    "- **정확도 (Accuracy)**: `(TP + TN) / (전체 데이터)`. 전체 예측 중 올바르게 예측한 비율. 데이터가 불균형할 때 모델 성능을 왜곡할 수 있습니다.\n",
    "\n",
    "- **정밀도 (Precision)**: `TP / (TP + FP)`. 모델이 'Positive'라고 예측한 것들 중 실제 'Positive'인 것의 비율. (예: 스팸 메일함의 신뢰도. FP를 낮추는 것이 중요할 때 사용)\n",
    "\n",
    "- **재현율 (Recall / Sensitivity)**: `TP / (TP + FN)`. 실제 'Positive'인 것들 중 모델이 'Positive'로 예측한 것의 비율. (예: 암 진단. 실제 환자를 놓치면 안 되므로 FN을 낮추는 것이 중요할 때 사용)\n",
    "\n",
    "- **F1-Score**: 정밀도와 재현율의 조화 평균. `2 * (Precision * Recall) / (Precision + Recall)`. 두 지표가 모두 중요할 때 사용되는 균형 잡힌 지표입니다.\n",
    "\n",
    "- **ROC Curve & AUC**: ROC 곡선은 재현율(TPR)을 Y축, 위양성률(FPR)을 X축으로 하여 그린 그래프입니다. 곡선이 좌측 상단에 가까울수록 좋은 모델이며, 곡선 아래의 면적인 **AUC(Area Under the Curve)** 값이 1에 가까울수록 성능이 좋다고 평가합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}