# 머신러닝 핵심 개념: 지도/비지도 학습, 스케일링, SVM, 이상치 처리 및 실전 적용

## 문서 목표
본 문서는 지도학습과 비지도학습의 기본 개념부터 데이터 스케일링 기법, 서포트 벡터 머신(SVM)의 원리, 이상치 탐지 및 처리 방법, 그리고 실제 데이터셋을 활용한 전처리 종합 실습까지 머신러닝의 핵심적인 내용들을 다룹니다. 또한, 모델 성능 분석과 실무 적용을 위한 가이드라인을 제시하여 머신러닝 프로젝트의 전반적인 이해를 돕습니다.

---

## 목차
- [1. 지도학습 vs 비지도학습](#1-지도학습-vs-비지도학습)
  - [1.1. 지도학습 (Supervised Learning)](#11-지도학습-supervised-learning)
  - [1.2. 비지도학습 (Unsupervised Learning)](#12-비지도학습-unsupervised-learning)
  - [1.3. 분류 vs 군집의 차이점](#13-분류-vs-군집의-차이점)
- [2. 데이터 스케일링](#2-데이터-스케일링)
  - [2.1. 스케일링의 필요성](#21-스케일링의-필요성)
  - [2.2. 스케일링 종류](#22-스케일링-종류)
- [3. 서포트벡터머신(SVM)](#3-서포트벡터머신svm)
  - [3.1. SVM의 핵심 개념](#31-svm의-핵심-개념)
  - [3.2. SVM 분류 예시 (스케일링의 중요성)](#32-svm-분류-예시-스케일링의-중요성)
  - [3.3. 주요 발견사항](#33-주요-발견사항)
  - [3.4. 수렴 문제 해결 방법](#34-수렴-문제-해결-방법)
- [4. 이상치 탐지 및 처리](#4-이상치-탐지-및-처리)
  - [4.1. IQR 방법을 이용한 이상치 탐지](#41-iqr-방법을-이용한-이상치-탐지)
  - [4.2. 이상치 처리 전략](#42-이상치-처리-전략)
- [5. 데이터 전처리 종합실습](#5-데이터-전처리-종합실습)
  - [5.1. 실습 데이터셋별 특징](#51-실습-데이터셋별-특징)
  - [5.2. 라벨 인코딩 기법](#52-라벨-인코딩-기법)
- [6. 성능 비교 및 분석](#6-성능-비교-및-분석)
  - [6.1. 종합 실험 결과](#61-종합-실험-결과)
  - [6.2. 핵심 인사이트](#62-핵심-인사이트)
  - [6.3. 성능 차이 (과적합 지표) 상세 설명](#63-성능-차이-과적합-지표-상세-설명)
- [7. 실무 적용 가이드](#7-실무-적용-가이드)
  - [7.1. 머신러닝 프로젝트 체크리스트](#71-머신러닝-프로젝트-체크리스트)
  - [7.2. 재사용 가능한 함수 템플릿](#72-재사용-가능한-함수-템플릿)
  - [7.3. 핵심 권장사항](#73-핵심-권장사항)
  - [7.4. 주의사항](#74-주의사항)
  - [7.5. 결론](#75-결론)

---

## 1. 지도학습 vs 비지도학습

### 1.1 지도학습 (Supervised Learning)
- **정의**: 출력결과(정답)를 알고 있을 때 사용하는 학습 방식
- **특징**: 레이블이 있는 데이터로 학습
- **사이킷런 패턴**: `fit()` → `predict()`
- **예시**: 분류, 회귀

### 1.2 비지도학습 (Unsupervised Learning)
- **정의**: 결과를 모르는 상태에서 패턴을 찾는 학습 방식
- **특징**: 라벨링이 없는 데이터 사용
- **사이킷런 패턴**: `fit()` → `transform()`
- **활용**: 지도학습 전단계 데이터 분석용으로 많이 사용
- **예시**: 군집화, 차원축소, 연관규칙분석

### 1.3 분류 vs 군집의 차이점

-   **분류 (Classification)**: 미리 정의된 레이블(클래스)이 있는 데이터를 학습하여 새로운 데이터가 어떤 레이블에 속할지 예측하는 지도 학습 기법입니다. 모델은 입력 특성과 레이블 간의 관계를 학습합니다.
    -   **예시**: "이 이미지는 기린일 확률이 0.7, 병아리일 확률이 0.3입니다." (정답이 '기린' 또는 '병아리'로 명확히 정해져 있음)
-   **군집 (Clustering)**: 레이블이 없는 데이터를 사용하여 데이터 내에 존재하는 자연스러운 그룹(클러스터)을 찾아내는 비지도 학습 기법입니다. 데이터 포인트 간의 유사성을 기반으로 그룹을 형성합니다.
    -   **예시**: "이 데이터는 클래스1에 속할 확률이 0.7, 클래스2에 속할 확률이 0.3입니다." (클래스1, 클래스2가 무엇인지는 사전에 정의되지 않고, 데이터로부터 발견된 그룹임)

## 2. 데이터 스케일링

### 2.1 스케일링의 필요성
- 서로 다른 단위와 범위를 가진 특성들을 통일
- 모델 성능 향상과 학습 안정성 확보
- 특히 거리 기반 알고리즘에서 필수적

### 2.2 스케일링 종류

#### 1. StandardScaler (표준화)
```python
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
scaled_data = ss.fit_transform(data)
```
- **특징**: 데이터의 평균을 0, 표준편차를 1로 변환하여 표준 정규 분포와 유사하게 만듭니다.
- **사용 시기**: 
  - 데이터가 정규 분포를 따른다고 가정할 때 (또는 정규 분포에 가깝게 만들고 싶을 때)
  - 선형 모델(로지스틱 회귀, SVM), 신경망 등 **거리 기반 또는 가중치 기반 모델**에서 특성들의 스케일 차이가 모델 성능에 큰 영향을 미칠 때 사용합니다.
- **단점**: 이상치(Outlier)에 민감하게 반응하여 변환된 값의 범위가 크게 왜곡될 수 있습니다.

#### 2. RobustScaler (로버스트 스케일링)
```python
from sklearn.preprocessing import RobustScaler
rb = RobustScaler()
scaled_data = rb.fit_transform(data)
```
- **특징**: 데이터의 중앙값(Median)과 사분위 범위(IQR: Interquartile Range)를 사용하여 스케일을 조정합니다.
- **사용 시기**: 데이터에 **이상치(Outlier)가 많을 때** 매우 효과적입니다. 이상치의 영향을 최소화하면서 데이터를 스케일링해야 할 경우에 사용합니다.
- **장점**: `StandardScaler`나 `MinMaxScaler`와 달리 이상치에 강건(robust)하여 데이터 분포를 왜곡시키지 않습니다.

#### 3. MinMaxScaler (최소-최대 정규화)
```python
from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
scaled_data = mm.fit_transform(data)
```
- **특징**: 특성값의 최솟값을 0, 최댓값을 1로 하여 모든 특성값을 0과 1 사이의 범위로 변환합니다.
- **사용 시기**: 
  - 특성값의 범위가 명확히 0~1 사이에 와야 할 때 (예: 이미지 픽셀 데이터, 특정 신경망의 입력)
  - 데이터의 분포가 균일하고 이상치가 적을 때 사용합니다.
- **단점**: 이상치에 매우 민감하여 이상치가 존재할 경우 데이터가 좁은 범위에 몰릴 수 있습니다.

#### 4. Normalizer (정규화)
```python
from sklearn.preprocessing import Normalizer
nm = Normalizer()
scaled_data = nm.fit_transform(data)
```
- **특징**: 각 샘플(행)의 유클리드 노름(L2 Norm)을 1로 만들어 벡터의 크기를 정규화합니다. 즉, 각 데이터 포인트(벡터)를 원점으로부터의 거리가 1인 단위 벡터로 변환합니다.
- **사용 시기**: 
  - 주로 텍스트 분류나 클러스터링(군집분석)에서 문서의 길이에 따른 영향을 제거하고 단어의 상대적 중요도를 반영할 때 유용합니다.
  - 코사인 유사도(Cosine Similarity)와 함께 사용될 때 효과적입니다.

## 3. 서포트벡터머신(SVM)

### 3.1 SVM의 핵심 개념
- **기본 아이디어**: 평면에 선을 그어 데이터를 분류
- **고차원 매핑**: 평면에서 분리가 어려운 경우 고차원 공간으로 변환
- **마진 최대화**: 클래스 간 경계를 최대한 멀리 설정

### 3.2 SVM 분류 예시 (스케일링의 중요성)

SVM은 특성들의 스케일에 매우 민감하게 반응하는 모델입니다. 아래 예시는 스케일링 적용 전후의 SVM 모델 성능 차이를 보여줍니다.

```python
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score

# 유방암 데이터셋 로드
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

# 1. 스케일링 없이 SVM 학습
svm_no_scale = SVC(random_state=0)
svm_no_scale.fit(X_train, y_train)
print(f"스케일링 없음 - 훈련 정확도: {svm_no_scale.score(X_train, y_train):.3f}")
print(f"스케일링 없음 - 테스트 정확도: {svm_no_scale.score(X_test, y_test):.3f}")

# 2. StandardScaler 적용 후 SVM 학습
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

svm_scaled = SVC(random_state=0)
svm_scaled.fit(X_train_scaled, y_train)
print(f"스케일링 적용 - 훈련 정확도: {svm_scaled.score(X_train_scaled, y_train):.3f}")
print(f"스케일링 적용 - 테스트 정확도: {svm_scaled.score(X_test_scaled, y_test):.3f}")
```

#### 유방암 데이터셋 실험 결과
| 모델 | 스케일링 | 훈련 정확도 | 테스트 정확도 |
|------|----------|-------------|---------------|
| 로지스틱 회귀 | 없음 | 94.6% | 94.4% |
| 로지스틱 회귀 | 적용 | 99.1% | 96.5% |
| SVM | 없음 | 90.4% | 93.7% |
| SVM | 적용 | 99.1% | 96.5% |

### 3.3 주요 발견사항
1. **SVM은 스케일링에 매우 민감**: 스케일링을 적용하지 않으면 성능이 크게 저하될 수 있습니다.
2. **로지스틱 회귀는 상대적으로 덜 민감하지만 수렴 속도 개선**: 로지스틱 회귀도 스케일링을 통해 학습 효율성과 성능을 높일 수 있습니다.
3. **스케일링 적용 시 두 모델 모두 성능 향상**: 특히 거리 기반 모델이나 경사하강법 기반 모델에서 스케일링은 필수적인 전처리 과정입니다.

### 3.4 수렴 문제 해결 방법
```python
# 방법 1: max_iter 증가
LogisticRegression(max_iter=1000)

# 방법 2: 데이터 스케일링 (권장)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

## 4. 이상치 탐지 및 처리

### 4.1 IQR 방법을 이용한 이상치 탐지

#### 계산 공식
- **Q1**: 25% 분위수
- **Q3**: 75% 분위수  
- **IQR**: Q3 - Q1
- **하한 경계**: Q1 - 1.5 × IQR
- **상한 경계**: Q3 + 1.5 × IQR

#### 실습 예제 결과

```python
import pandas as pd
import numpy as np

# 가상 데이터 생성
data = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100])

# Q1, Q3 계산
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

# 이상치 경계 계산
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

print(f"Q1: {Q1}")
print(f"Q3: {Q3}")
print(f"IQR: {IQR}")
print(f"하한 경계: {lower_bound}")
print(f"상한 경계: {upper_bound}")

# 이상치 탐지
outliers = data[(data < lower_bound) | (data > upper_bound)]
print(f"탐지된 이상치: {outliers.tolist()}")

# 이상치 제거 (예시)
data_cleaned = data[(data >= lower_bound) & (data <= upper_bound)]
print(f"이상치 제거 후 데이터 (일부): {data_cleaned.tolist()}")
print(f"처리 전: 평균 {data.mean():.2f}, 표준편차 {data.std():.2f}")
print(f"처리 후: 평균 {data_cleaned.mean():.2f}, 표준편차 {data_cleaned.std():.2f}")
```

### 4.2 이상치 처리 전략
1. **제거**: 완전히 삭제
2. **대체**: 경계값으로 변경 (Winsorizing)
3. **변환**: 로그 변환 등을 통한 완화

## 5. 데이터 전처리 종합실습

### 5.1 실습 데이터셋별 특징

#### 1. Iris 데이터셋
- **특징**: 깨끗한 데이터, 결측치 없음
- **크기**: 150개 샘플, 4개 특성
- **목표**: 3종류 붓꽃 분류
- **전처리**: 불필요
- **성능**: 훈련 97.1%, 테스트 93.3%

#### 2. Penguins 데이터셋  
- **특징**: 결측치 존재, 범주형 데이터 포함
- **크기**: 333개 샘플, 6개 특성
- **목표**: 3종류 펭귄 분류
- **전처리**: 라벨 인코딩 + 결측치 제거
- **성능**: 훈련 99.1%, 테스트 99.0%

#### 3. Diamonds 데이터셋
- **특징**: 복잡한 범주형 변수 다수
- **크기**: 53,940개 샘플, 9개 특성
- **목표**: 5종류 다이아몬드 컷 분류
- **전처리**: 자동화된 라벨 인코딩
- **성능**: 훈련 54.3%, 테스트 54.0%

### 5.2 라벨 인코딩 기법

#### 수동 매핑 방식
```python
island_mapping = {'Torgersen': 1, 'Dream': 2, 'Biscoe': 3}
df['island_label'] = df['island'].map(island_mapping)
```

#### 자동화된 매핑 함수
```python
def get_label_map(df, field):
    """DataFrame과 필드명을 입력받아 고유값에 대한 라벨 매핑 딕셔너리를 생성합니다.
    라벨은 1부터 시작하는 정수입니다.
    """
    unique_values = df[field].unique()
    label_map = {item: index + 1 for index, item in enumerate(unique_values)}
    return label_map

# 사용 예시:
# df_penguins = pd.DataFrame({'island': ['Torgersen', 'Dream', 'Biscoe', 'Torgersen']})
# island_label_map = get_label_map(df_penguins, 'island')
# print(island_label_map) # 출력: {'Torgersen': 1, 'Dream': 2, 'Biscoe': 3}
# df_penguins['island_label'] = df_penguins['island'].map(island_label_map)
# print(df_penguins)
```

## 6. 성능 비교 및 분석

### 6.1 종합 실험 결과

| 데이터셋 | 훈련 정확도 | 테스트 정확도 | 성능 차이 (과적합 지표) | 전처리 복잡도 |
|----------|-------------|---------------|--------------------------|---------------|
| Iris | 0.971 | 0.933 | 0.038 (양호) | 낮음 |
| Penguins | 0.991 | 0.990 | 0.001 (양호) | 중간 |
| Diamonds | 0.543 | 0.540 | 0.003 (양호) | 높음 |

### 6.2 핵심 인사이트
1. **데이터 품질이 모델 성능에 결정적 영향**: 깨끗하고 잘 정제된 데이터는 모델의 학습 효율과 예측 정확도를 크게 향상시킵니다.
2. **적절한 전처리는 성공적인 머신러닝의 핵심**: 데이터의 특성과 모델의 요구사항에 맞는 전처리 기법(스케일링, 인코딩, 결측치/이상치 처리 등)을 적용하는 것이 중요합니다.
3. **과적합 위험도**: 훈련 정확도와 테스트 정확도 간의 차이(gap)가 클수록 과적합 위험이 높습니다. Iris 데이터셋은 다른 데이터셋에 비해 상대적으로 과적합 위험이 높았으나, 여전히 허용 가능한 범위 내였습니다.
4. **전처리 복잡도와 성능은 반드시 비례하지 않음**: Diamonds 데이터셋은 전처리 복잡도가 높았음에도 불구하고 Iris나 Penguins 데이터셋에 비해 절대적인 성능(정확도)이 낮았습니다. 이는 데이터 자체의 복잡성이나 내재된 한계 때문일 수 있습니다.

### 6.3 성능 차이 (과적합 지표) 상세 설명

**성능 차이 (Gap)**는 `훈련 정확도 - 테스트 정확도`로 계산됩니다. 이 값은 모델이 훈련 데이터에 얼마나 과적합되었는지를 나타내는 중요한 지표입니다.

*   **Gap이 작을수록 (예: 0.1 이하)**: 모델이 훈련 데이터에 과적합되지 않고 새로운 데이터에 대해서도 좋은 일반화 성능을 보인다는 의미입니다. 이는 모델이 데이터의 일반적인 패턴을 잘 학습했음을 시사합니다.
*   **Gap이 클수록 (예: 0.1 초과)**: 모델이 훈련 데이터에 과도하게 맞춰져 훈련 데이터의 노이즈까지 학습했음을 의미합니다. 이 경우, 모델은 새로운 데이터에 대해 낮은 예측 성능을 보일 가능성이 높습니다. 이는 과적합의 명확한 신호이며, 규제(Regularization), 데이터 증강(Data Augmentation), 하이퍼파라미터 튜닝 등을 통해 해결해야 합니다.

## 7. 실무 적용 가이드

### 7.1 머신러닝 프로젝트 체크리스트

#### 데이터 탐색 단계
- [ ] 데이터 크기 및 구조 파악 (`shape`, `info()`)
- [ ] 기술 통계 확인 (`describe()`)
- [ ] 결측치 현황 조사 (`isnull().sum()`)
- [ ] 타겟 변수 분포 확인 (`value_counts()`)
- [ ] 범주형/수치형 변수 구분

#### 데이터 전처리 단계
- [ ] **결측치 처리**: 제거 vs 대체 전략 결정
- [ ] **이상치 탐지**: 박스플롯, IQR 방법 활용
- [ ] **범주형 인코딩**: 라벨 인코딩 vs 원핫 인코딩
- [ ] **스케일링**: 필요시 StandardScaler 적용
- [ ] **특성 선택**: 상관관계, 중요도 기반 선택

#### 모델링 단계
- [ ] **데이터 분할**: train_test_split with stratify
- [ ] **모델 선택**: 문제 유형에 적합한 알고리즘
- [ ] **하이퍼파라미터**: max_iter, random_state 설정

#### 평가 및 개선 단계
- [ ] **성능 지표**: 정확도, 정밀도, 재현율
- [ ] **과적합 확인**: 훈련-테스트 성능 차이 < 0.1
- [ ] **예측 샘플**: 실제 예측 결과 확인

### 7.2 재사용 가능한 함수 템플릿

#### 범주형 데이터 자동 인코딩
```python
def preprocess_categorical_data(df, categorical_columns):
    """범주형 데이터 자동 라벨 인코딩"""
    df_encoded = df.copy()
    mappings = {}
    
    for col in categorical_columns:
        unique_values = df[col].unique()
        mapping = {val: idx+1 for idx, val in enumerate(unique_values)}
        df_encoded[f'{col}_label'] = df_encoded[col].map(mapping)
        mappings[col] = mapping
    
    return df_encoded, mappings
```

#### 모델 성능 평가 표준화
```python
def evaluate_model(model, X_train, X_test, y_train, y_test, dataset_name):
    """모델 성능 평가 표준화"""
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)
    gap = train_score - test_score
    
    print(f"=== {dataset_name} 결과 ---")
    print(f"훈련 정확도: {train_score:.4f}")
    print(f"테스트 정확도: {test_score:.4f}")
    print(f"성능 차이: {gap:.4f}")
    print(f"과적합: {'위험' if gap > 0.1 else '양호'}")
    
    return train_score, test_score, gap
```

### 7.3 핵심 권장사항

1. **항상 데이터 탐색(EDA)부터 시작**
2. **전처리 과정을 함수화하여 재사용성 향상**
3. **훈련-테스트 성능 차이 0.1 이하 유지**
4. **SVM과 같은 거리 기반 알고리즘에서는 반드시 스케일링 적용**
5. **결측치 처리 전략을 신중하게 결정**
6. **범주형 데이터는 적절한 인코딩 기법 선택**

### 7.4 주의사항

1. **데이터 누수 방지 (Data Leakage Prevention)**: 모델 학습 과정에서 테스트 데이터(또는 검증 데이터)의 정보가 훈련 데이터에 유출되지 않도록 주의해야 합니다. 예를 들어, 전체 데이터셋에 대해 스케일링을 `fit_transform`하거나, 결측치를 대체한 후 훈련/테스트 세트를 분할하는 것은 데이터 누수를 발생시킵니다. 올바른 방법은 훈련 세트에서 `fit_transform`을 수행하고, 테스트 세트에는 훈련 세트에서 학습된 파라미터로 `transform`만 적용하는 것입니다.
2. **랜덤 시드 고정**: 재현 가능한 결과를 위해 random_state 설정
3. **레이블 매핑 보존**: 인코딩 매핑 정보 저장 및 관리
4. **성능 모니터링**: 지속적인 과적합 여부 확인

### 7.5 결론

"별짓 다해도 데이터가 많아야 한다!" - 데이터의 품질과 양이 머신러닝 성공의 핵심 요소입니다.

---

[⏮️ 이전 문서](./0708_ML정리.md) | [다음 문서 ⏭️](./0710_ML정리.md)