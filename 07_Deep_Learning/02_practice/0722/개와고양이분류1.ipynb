{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개와 고양이 분류 (CNN 모델 직접 구축)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 전이 학습(Transfer Learning)을 사용하지 않고, 처음부터 직접 합성곱 신경망(CNN)을 구축하여 개와 고양이 이미지를 분류합니다. \n",
    "\n",
    "**프로세스:**\n",
    "1. **데이터 준비**: Kaggle의 \"Dogs vs. Cats\" 데이터셋을 다운로드하고, 손상된 파일을 제거한 후, 훈련(train), 검증(validation), 테스트(test)용으로 데이터를 분할합니다.\n",
    "2. **데이터 로딩**: `image_dataset_from_directory`를 사용하여 디렉토리에서 이미지를 효율적으로 로드합니다.\n",
    "3. **모델 구축**: 데이터 증강(Data Augmentation)을 포함한 간단한 CNN 모델을 정의합니다.\n",
    "4. **학습 및 평가**: 모델을 학습시키고, 학습 과정을 시각화한 후, 테스트 데이터셋으로 최종 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터셋 다운로드 및 손상된 파일 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
    "zip_path = tf.keras.utils.get_file('kagglecatsanddogs.zip', origin=dataset_url, extract=True)\n",
    "original_dir = pathlib.Path(zip_path).parent / 'PetImages'\n",
    "\n",
    "# 손상된 이미지 제거\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = original_dir / folder_name\n",
    "    if not folder_path.is_dir(): continue\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = folder_path / fname\n",
    "        if not fpath.is_file(): continue\n",
    "        try:\n",
    "            with open(fpath, \"rb\") as fobj:\n",
    "                is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        except Exception:\n",
    "            is_jfif = False\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            os.remove(fpath)\n",
    "print(f\"손상된 이미지 {num_skipped}개를 삭제했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 훈련/검증/테스트용 서브셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir = pathlib.Path(\"./cats_vs_dogs_small_scratch\")\n",
    "if not new_base_dir.exists():\n",
    "    print(\"훈련, 검증, 테스트 서브셋을 새로 생성합니다...\")\n",
    "    for subset_name, start, end in [(\"train\", 0, 1000), (\"validation\", 1000, 1500), (\"test\", 1500, 2000)]:\n",
    "        for category in (\"Cat\", \"Dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = sorted(os.listdir(original_dir / category))[start:end]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / category / fname, dst=dir / fname)\n",
    "else:\n",
    "    print(\"서브셋 디렉토리가 이미 존재하여 재생성하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (180, 180)\n",
    "\n",
    "train_ds = image_dataset_from_directory(new_base_dir / \"train\", image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\n",
    "validation_ds = image_dataset_from_directory(new_base_dir / \"validation\", image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\n",
    "test_ds = image_dataset_from_directory(new_base_dir / \"test\", image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN 모델 정의 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 레이어\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# 모델 구성\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50, # 에포크 수를 늘려 충분히 학습\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최종 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "\n",
    "print(\"테스트 데이터셋으로 최종 모델을 평가합니다...\")\n",
    "test_loss, test_acc = best_model.evaluate(test_ds)\n",
    "print(f'최종 테스트 정확도: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}