{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개와 고양이 분류 (사전 학습 모델 VGG19 활용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 사전 학습된 VGG19 모델을 사용하여 개와 고양이 이미지를 분류합니다. \n",
    "다음과 같은 **2단계 특성 추출(Two-Stage Feature Extraction)** 방식을 사용합니다:\n",
    "1. **특성 추출**: VGG19의 합성곱 기반(Convolutional Base)을 사용하여 이미지에서 특성을 추출하고, 이 결과를 `.npy` 파일로 저장합니다.\n",
    "2. **분류기 학습**: 저장된 특성을 입력으로 사용하여 새로운 소규모 완전 연결(Fully Connected) 분류기를 학습시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터셋 다운로드 및 압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle의 'Dogs vs. Cats' 원본 데이터셋 URL\n",
    "dataset_url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
    "\n",
    "# 데이터셋 다운로드 및 압축 해제\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    'kagglecatsanddogs.zip',\n",
    "    origin=dataset_url,\n",
    "    extract=True\n",
    ")\n",
    "\n",
    "# 원본 데이터 경로 설정 (PetImages 폴더 안에 Cat, Dog 폴더가 있음)\n",
    "original_dir = pathlib.Path(zip_path).parent / 'PetImages'\n",
    "print(f\"원본 데이터 경로: {original_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 손상된 이미지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 이미지가 손상되어 있어 학습 오류를 유발할 수 있으므로 제거합니다.\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = original_dir / folder_name\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = folder_path / fname\n",
    "        try:\n",
    "            # 파일 헤더를 확인하여 유효한 이미지인지 검사\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # 손상된 파일 삭제\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(f\"손상된 이미지 {num_skipped}개를 삭제했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 훈련/검증/테스트용 서브셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir = pathlib.Path(\"./cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"Cat\", \"Dog\"):\n",
    "        # 서브셋 디렉토리 생성 (e.g., ./cats_vs_dogs_small/train/Cat)\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        if not dir.exists():\n",
    "            os.makedirs(dir)\n",
    "        \n",
    "        # 원본 디렉토리에서 파일 이름 목록 생성\n",
    "        fnames = [f for f in os.listdir(original_dir / category)]\n",
    "        # 지정된 범위의 파일만 선택\n",
    "        selected_fnames = fnames[start_index:end_index]\n",
    "        \n",
    "        for fname in selected_fnames:\n",
    "            shutil.copyfile(src=original_dir / category / fname, dst=dir / fname)\n",
    "    print(f\"'{subset_name}' 서브셋 생성 완료.\")\n",
    "\n",
    "# 이미 서브셋이 존재하면 다시 생성하지 않음\n",
    "if not new_base_dir.exists():\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2000)\n",
    "else:\n",
    "    print(\"서브셋 디렉토리가 이미 존재합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사전 학습된 모델(VGG19) 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = applications.vgg19.VGG19(\n",
    "    weights=\"imagenet\",      # ImageNet으로 사전 학습된 가중치 사용\n",
    "    include_top=False,       # 분류기(Fully Connected Layer)는 제외하고 합성곱 기반만 로드\n",
    "    input_shape=(180, 180, 3) # 입력 이미지 크기 지정\n",
    ")\n",
    "\n",
    "# VGG19의 합성곱 기반은 학습되지 않도록 동결\n",
    "conv_base.trainable = False\n",
    "\n",
    "print(\"VGG19 합성곱 기반 모델 요약:\")\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 특성 추출 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 데이터셋 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (180, 180)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "test_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. VGG19를 이용한 특성 및 레이블 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        # VGG19 모델에 맞는 전처리 적용\n",
    "        preprocessed_images = applications.vgg19.preprocess_input(images)\n",
    "        # conv_base를 통해 특성 추출\n",
    "        features = conv_base.predict(preprocessed_images, verbose=0)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    # 리스트를 하나의 넘파이 배열로 결합\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "print(\"훈련 데이터에서 특성을 추출합니다...\")\n",
    "train_features, train_labels = get_features_and_labels(train_ds)\n",
    "print(\"검증 데이터에서 특성을 추출합니다...\")\n",
    "validation_features, validation_labels = get_features_and_labels(validation_ds)\n",
    "print(\"테스트 데이터에서 특성을 추출합니다...\")\n",
    "test_features, test_labels = get_features_and_labels(test_ds)\n",
    "\n",
    "print(\"\\n추출된 훈련 특성의 형태:\", train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 분류기 모델 정의 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**: 원본 스크립트의 데이터 증강(Data Augmentation)은 특성 맵(`5x5x512`)에 적용되어 오류를 유발하므로 여기서는 제외했습니다. 데이터 증강은 원본 이미지(`180x180x3`)에 적용되어야 합니다. 올바른 방식은 `conv_base`와 새로운 분류기를 하나의 모델로 합친 후, 이미지 데이터셋을 직접 학습시키는 것입니다(인라인 방식)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19의 출력 형태(5, 5, 512)를 입력으로 받는 새로운 분류기 모델 정의\n",
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) # 이진 분류 (개/고양이)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 가장 성능이 좋은 모델을 저장하기 위한 콜백 설정\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction_model.keras\",\n",
    "        save_best_only=True,      # 가장 좋은 모델만 저장\n",
    "        monitor=\"val_loss\"        # 검증 손실을 기준으로 판단\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20, # 에포크 수를 20으로 늘려 충분히 학습\n",
    "    validation_data=(validation_features, validation_labels),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 평가 (테스트 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 최적의 모델을 로드\n",
    "best_model = keras.models.load_model(\"feature_extraction_model.keras\")\n",
    "\n",
    "print(\"테스트 데이터셋으로 최종 모델을 평가합니다...\")\n",
    "test_loss, test_acc = best_model.evaluate(test_features, test_labels)\n",
    "print(f'테스트 정확도: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}