{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개와 고양이 분류 (사전 학습 모델 VGG19 - 인라인 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 사전 학습된 VGG19 모델을 사용하여 개와 고양이 이미지를 분류합니다. \n",
    "**인라인(Inline) 특성 추출** 방식을 사용하여, VGG19의 합성곱 기반(Convolutional Base)과 새로운 분류기를 하나의 모델로 통합합니다.\n",
    "\n",
    "**장점:**\n",
    "- 데이터 증강(Data Augmentation)이 원본 이미지에 직접 적용되어 과적합을 효과적으로 방지합니다.\n",
    "- 전체 프로세스가 단일 모델 학습으로 이루어져 코드가 더 간결합니다.\n",
    "\n",
    "**단점:**\n",
    "- 2단계 방식보다 학습 속도가 느립니다 (매 에포크마다 VGG19 특성 추출을 반복해야 함)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터셋 다운로드 및 손상된 파일 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
    "zip_path = tf.keras.utils.get_file('kagglecatsanddogs.zip', origin=dataset_url, extract=True)\n",
    "original_dir = pathlib.Path(zip_path).parent / 'PetImages'\n",
    "\n",
    "# 손상된 이미지 제거 (파일이 아니거나 읽을 수 없는 파일 포함)\n",
    "print(f\"원본 데이터 경로: {original_dir}\")\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = original_dir / folder_name\n",
    "    if not folder_path.is_dir():\n",
    "        print(f\"경고: '{folder_path}' 디렉토리를 찾을 수 없습니다.\")\n",
    "        continue\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = folder_path / fname\n",
    "        # 파일이 아니면 건너뛰기\n",
    "        if not fpath.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            with open(fpath, \"rb\") as fobj:\n",
    "                is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        except Exception as e:\n",
    "            # 파일을 열거나 읽는 데 실패하면 손상된 것으로 간주\n",
    "            print(f\"파일 읽기 오류 {fpath}: {e}\")\n",
    "            is_jfif = False\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(f\"손상되었거나 읽을 수 없는 이미지 {num_skipped}개를 삭제했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 훈련/검증/테스트용 서브셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir = pathlib.Path(\"./cats_vs_dogs_small_inline\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"Cat\", \"Dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        \n",
    "        # 재현성을 위해 파일 목록을 정렬\n",
    "        fnames = sorted(os.listdir(original_dir / category))\n",
    "        selected_fnames = fnames[start_index:end_index]\n",
    "        \n",
    "        for fname in selected_fnames:\n",
    "            shutil.copyfile(src=original_dir / category / fname, dst=dir / fname)\n",
    "            \n",
    "    # 생성된 파일 수 확인\n",
    "    cat_count = len(os.listdir(new_base_dir / subset_name / 'Cat'))\n",
    "    dog_count = len(os.listdir(new_base_dir / subset_name / 'Dog'))\n",
    "    print(f\"'{subset_name}' 서브셋 생성 완료: Cats={cat_count}, Dogs={dog_count}\")\n",
    "\n",
    "# 서브셋 디렉토리가 비어있을 경우에만 생성\n",
    "if not new_base_dir.exists() or not any((new_base_dir / 'train').iterdir()):\n",
    "    print(\"훈련, 검증, 테스트 서브셋을 새로 생성합니다...\")\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2000)\n",
    "else:\n",
    "    print(\"서브셋 디렉토리가 이미 존재하여 재생성하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의 (인라인 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 데이터 증강 및 VGG19 기반 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 레이어\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "]) \n",
    "\n",
    "# VGG19 합성곱 기반 로드\n",
    "conv_base = applications.vgg19.VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3)\n",
    ")\n",
    "\n",
    "# VGG19의 가중치가 훈련 중에 업데이트되지 않도록 동결\n",
    "conv_base.trainable = False\n",
    "\n",
    "print(f\"VGG19 동결 전 훈련 가능 가중치 수: {len(conv_base.trainable_weights)}\")\n",
    "print(f\"VGG19 동결 후 훈련 가능 가중치 수: {len(conv_base.trainable_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 전체 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# 1. 데이터 증강\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# 2. VGG19에 맞는 전처리\n",
    "x = applications.vgg19.preprocess_input(x)\n",
    "\n",
    "# 3. VGG19 특성 추출\n",
    "x = conv_base(x)\n",
    "\n",
    "# 4. 새로운 분류기\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (180, 180)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "test_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"inline_feature_extraction.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=30, # 충분한 학습을 위해 에포크 수 증가\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"inline_feature_extraction.keras\")\n",
    "\n",
    "print(\"테스트 데이터셋으로 최종 모델을 평가합니다...\")\n",
    "test_loss, test_acc = best_model.evaluate(test_ds)\n",
    "print(f'테스트 정확도: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}