{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 꽃 이미지 분류 (VGG19 전이 학습)\n",
    "\n",
    "이 노트북은 강력한 사전 훈련된 모델인 **VGG19**를 사용하여 꽃 이미지를 분류하는 **전이 학습(Transfer Learning)** 기법을 다룹니다. 전이 학습은 대규모 데이터셋(예: ImageNet)으로 미리 학습된 모델의 지식을 가져와, 더 작은 데이터셋에 맞게 조정하여 사용하는 강력한 방법입니다.\n",
    "\n",
    "**주요 과정:**\n",
    "1.  **데이터셋 재구성**: 원본 데이터셋을 `train`과 `test` 폴더로 분리하여 모델 학습에 적합한 구조로 만듭니다.\n",
    "2.  **데이터 로딩**: Keras의 `image_dataset_from_directory` 유틸리티를 사용하여 디스크에서 직접 이미지를 효율적으로 로드하고, 훈련/검증 세트를 나눕니다.\n",
    "3.  **VGG19 모델 로드**: ImageNet으로 사전 학습된 VGG19 모델의 합성곱 기반(convolutional base)을 불러옵니다.\n",
    "4.  **모델 동결**: 불러온 VGG19의 가중치가 훈련 중에 업데이트되지 않도록 동결(freeze)합니다.\n",
    "5.  **데이터 증강**: 훈련 데이터에 무작위 변환을 적용하여 과대적합을 줄이고 모델의 일반화 성능을 높입니다.\n",
    "6.  **새로운 모델 구축**: 동결된 VGG19 기반 위에 새로운 분류기(classifier)를 추가하여 최종 모델을 완성합니다.\n",
    "7.  **모델 훈련 및 평가**: 구축된 모델을 훈련하고, 테스트 데이터셋으로 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 임포트 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# 경로 설정\n",
    "original_dir = pathlib.Path(\"../data/flowers\")\n",
    "new_base_dir = pathlib.Path(\"../data/new_flowers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 재구성\n",
    "Keras의 데이터 로딩 유틸리티를 효율적으로 사용하기 위해, 원본 데이터셋을 `train`과 `test` 하위 디렉토리로 복사하여 재구성합니다. 이 작업은 한 번만 수행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'..\\data\\new_flowers'가 이미 존재합니다. 데이터 재구성을 건너뜁니다.\n"
     ]
    }
   ],
   "source": [
    "def make_subset(subset_name, start_index, end_index):\n",
    "    \"\"\"주어진 인덱스 범위에 따라 데이터의 서브셋을 만듭니다.\"\"\"\n",
    "    for category in (\"daisy\", \"dandelion\", \"tulip\", \"rose\", \"sunflower\"):\n",
    "        dir_path = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        \n",
    "        source_dir = original_dir / category\n",
    "        data_list = [f for f in os.listdir(source_dir) if os.path.isfile(source_dir / f)]\n",
    "        \n",
    "        if end_index is not None:\n",
    "            fnames = data_list[start_index:end_index]\n",
    "        else:\n",
    "            fnames = data_list[start_index:]\n",
    "            \n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=source_dir / fname, dst=dir_path / fname)\n",
    "\n",
    "# new_base_dir이 이미 존재하면 재구성 작업을 건너뜁니다.\n",
    "if not os.path.exists(new_base_dir):\n",
    "    print(f\"'{new_base_dir}'를 생성하고 데이터를 재구성합니다...\")\n",
    "    # 각 클래스별로 700개 이미지를 훈련용으로, 나머지를 테스트용으로 분리\n",
    "    make_subset(\"train\", 0, 700)\n",
    "    make_subset(\"test\", 700, None)\n",
    "    print(\"데이터 재구성 완료.\")\n",
    "else:\n",
    "    print(f\"'{new_base_dir}'가 이미 존재합니다. 데이터 재구성을 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TensorFlow 데이터셋 생성\n",
    "`image_dataset_from_directory`를 사용하여 디스크에서 직접 이미지를 로드하는 `tf.data.Dataset` 객체를 생성합니다. 이 방식은 메모리를 효율적으로 사용하게 해줍니다.\n",
    "\n",
    "- 훈련 데이터(`train_ds`)는 다시 8:2 비율로 나뉘어 실제 훈련용과 검증용(`validation_ds`)으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 1 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory ..\\data\\new_flowers\\train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 훈련 데이터셋 (80%)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_ds = \u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_base_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1234\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m180\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 검증 데이터셋 (20%)\u001b[39;00m\n\u001b[32m     12\u001b[39m validation_ds = image_dataset_from_directory(\n\u001b[32m     13\u001b[39m     new_base_dir / \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     seed=\u001b[32m1234\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     batch_size=\u001b[32m16\u001b[39m\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\anaconda3\\envs\\aiops\\Lib\\site-packages\\keras\\src\\utils\\image_dataset.py:303\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[39m\n\u001b[32m    299\u001b[39m image_paths, labels = dataset_utils.get_training_or_validation_split(\n\u001b[32m    300\u001b[39m     image_paths, labels, validation_split, subset\n\u001b[32m    301\u001b[39m )\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    304\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m     )\n\u001b[32m    308\u001b[39m dataset = paths_and_labels_to_dataset(\n\u001b[32m    309\u001b[39m     image_paths=image_paths,\n\u001b[32m    310\u001b[39m     image_size=image_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m     crop_to_aspect_ratio=crop_to_aspect_ratio,\n\u001b[32m    317\u001b[39m )\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: No images found in directory ..\\data\\new_flowers\\train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터셋 (80%)\n",
    "train_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    seed=1234,\n",
    "    subset='training',\n",
    "    validation_split=0.2,\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# 검증 데이터셋 (20%)\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    seed=1234,\n",
    "    subset='validation',\n",
    "    validation_split=0.2,\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋\n",
    "test_ds = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(\"\\n클래스 이름:\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. VGG19 모델 로드 및 동결\n",
    "ImageNet으로 사전 학습된 VGG19 모델의 합성곱 부분만 불러옵니다 (`include_top=False`). 그 후, 이 사전 학습된 가중치들이 훈련 중에 변경되지 않도록 동결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg19.VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3)\n",
    ")\n",
    "\n",
    "print(\"동결 전 훈련 가능 가중치 수:\", len(conv_base.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print(\"동결 후 훈련 가능 가중치 수:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터 증강 및 최종 모델 구축\n",
    "과대적합을 방지하기 위해 데이터 증강 레이어를 정의합니다. 그 후, Keras의 함수형 API를 사용하여 VGG19 베이스와 새로운 분류기를 연결하여 최종 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 레이어\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.4)\n",
    "])\n",
    "\n",
    "# 모델 구축\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs) # 1. 데이터 증강\n",
    "x = keras.applications.vgg19.preprocess_input(x) # 2. VGG19에 맞는 전처리\n",
    "x = conv_base(x) # 3. VGG19 기반으로 특징 추출\n",
    "x = layers.Flatten()(x) # 4. 1차원으로 펼치기\n",
    "x = layers.Dense(256)(x) # 5. 새로운 분류기\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dense(64)(x)\n",
    "outputs = layers.Dense(5, activation='softmax')(x) # 6. 최종 출력층\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 훈련\n",
    "`ModelCheckpoint` 콜백을 사용하여 검증 손실이 가장 낮은 최적의 모델을 저장하면서 훈련을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"flowers_vgg19.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss'\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=5, # 데모를 위해 에포크 수를 줄임 (원래는 더 많이 필요)\n",
    "                    validation_data=validation_ds,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# 훈련 기록 저장\n",
    "with open(\"flowers_vgg19_history.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가 및 결과 시각화\n",
    "훈련된 모델의 최종 성능을 평가하고, 훈련 과정 동안의 손실과 정확도 변화를 그래프로 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 저장된 최적 모델 로드 및 평가\n",
    "print(\"\\n--- 최종 모델 평가 (테스트 데이터셋) ---\")\n",
    "best_model = keras.models.load_model(\"flowers_vgg19.keras\")\n",
    "test_loss, test_acc = best_model.evaluate(test_ds)\n",
    "print(f\"테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
