{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 꽃 이미지 분류 (CNN 방식)\n",
    "\n",
    "이 노트북은 데이지(daisy)와 민들레(dandelion) 이미지를 분류하는 **합성곱 신경망(Convolutional Neural Network, CNN)** 모델을 구축합니다. 이전의 완전 연결 신경망(DNN) 방식과 달리, CNN은 이미지의 공간적 특징(spatial features)을 직접 학습할 수 있어 이미지 분류 작업에 훨씬 더 효과적입니다.\n",
    "\n",
    "**주요 차이점:**\n",
    "- **모델 구조**: `Conv2D`와 `MaxPooling2D` 레이어를 사용하여 이미지의 특징을 추출합니다.\n",
    "- **데이터 형태**: 이미지를 1차원 벡터로 펼치지 않고, `(높이, 너비, 채널)` 형태의 3차원 데이터를 그대로 사용합니다.\n",
    "- **전처리**: `StandardScaler` 대신 픽셀 값을 0-1 범위로 정규화하는 간단한 스케일링을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 임포트 및 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as pilimg\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# 기본 경로 설정\n",
    "base_path = \"./data/flowers2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 준비: 이미지 파일을 NumPy 배열로 변환\n",
    "\n",
    "모든 이미지를 일정한 크기(80x80)로 조정하고 NumPy 배열로 변환하여 `.npz` 파일로 저장합니다. 이 과정은 이전 노트북에서 이미 실행했다면 건너뛸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_from_images(flower_name, label, is_train=True):\n",
    "    \"\"\"특정 꽃 이미지를 읽어 npz 파일로 저장합니다.\"\"\"\n",
    "    path_type = \"train\" if is_train else \"test\"\n",
    "    path = os.path.join(base_path, path_type, flower_name)\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"'{flower_name}' ({path_type}) 카테고리 처리 시작...\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"  경로를 찾을 수 없습니다: {path}\")\n",
    "        return\n",
    "        \n",
    "    filenames = os.listdir(path)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  {i + 1} / {len(filenames)} 번째 파일 처리 중...\")\n",
    "        \n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if imghdr.what(file_path) in [\"gif\", \"png\", \"jpeg\", \"jpg\"]:\n",
    "                img = pilimg.open(file_path)\n",
    "                resize_img = img.resize((80, 80))\n",
    "                pixel = np.array(resize_img)\n",
    "                if pixel.shape == (80, 80, 3):\n",
    "                    data.append(pixel)\n",
    "                    labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"  파일 처리 오류: {filename}, 오류: {e}\")\n",
    "\n",
    "    save_filename = f\"imagedata_{label}_{path_type}.npz\"\n",
    "    np.savez(save_filename, data=data, targets=labels)\n",
    "    print(f\"'{flower_name}' ({path_type}) 데이터 저장 완료 -> {save_filename}\")\n",
    "\n",
    "def initialize_dataset():\n",
    "    \"\"\"모든 카테고리에 대해 데이터 생성을 수행합니다.\"\"\"\n",
    "    if len(glob.glob('imagedata_*.npz')) >= 4:\n",
    "        print(\"이미 전처리된 .npz 파일들이 존재합니다. 데이터 생성을 건너뜁니다.\")\n",
    "        return\n",
    "\n",
    "    flowers = [\"daisy\", \"dandelion\"]\n",
    "    for i, f in enumerate(flowers):\n",
    "        make_data_from_images(f, i, is_train=True)\n",
    "        make_data_from_images(f, i, is_train=False)\n",
    "    print(\"\\n모든 데이터 저장 완료.\")\n",
    "\n",
    "# 데이터 준비 함수 실행\n",
    "initialize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 로딩 및 전처리 (CNN 방식)\n",
    "CNN 모델은 이미지의 2D 구조를 그대로 입력받으므로, 데이터를 1차원 벡터로 펼치지 않습니다. 픽셀 값을 0-1 사이로 정규화하는 스케일링만 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_for_cnn():\n",
    "    \"\"\"npz 파일들을 로드하고 CNN에 맞게 전처리합니다.\"\"\"\n",
    "    with np.load(\"imagedata_0_train.npz\") as f1, np.load(\"imagedata_1_train.npz\") as f2:\n",
    "        X_train = np.concatenate((f1[\"data\"], f2[\"data\"]), axis=0)\n",
    "        y_train = np.concatenate((f1[\"targets\"], f2[\"targets\"]), axis=0)\n",
    "\n",
    "    with np.load(\"imagedata_0_test.npz\") as f1, np.load(\"imagedata_1_test.npz\") as f2:\n",
    "        X_test = np.concatenate((f1[\"data\"], f2[\"data\"]), axis=0)\n",
    "        y_test = np.concatenate((f1[\"targets\"], f2[\"targets\"]), axis=0)\n",
    "        \n",
    "    # 스케일링 (0-1 범위로 정규화)\n",
    "    X_train_scaled = X_train.astype('float32') / 255.0\n",
    "    X_test_scaled = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_and_preprocess_for_cnn()\n",
    "\n",
    "print(\"--- CNN용 데이터 형태 ---\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CNN 모델 구축\n",
    "합성곱 신경망(CNN) 모델을 정의합니다.\n",
    "- **Conv2D & MaxPooling2D**: 이미지의 특징을 효과적으로 추출하고 다운샘플링하는 부분입니다.\n",
    "- **Flatten**: 추출된 2D 특징 맵을 1D 벡터로 변환하여 완전 연결층에 전달합니다.\n",
    "- **Dense**: 최종적으로 클래스를 분류하는 부분입니다. 이진 분류이므로 마지막 층은 `sigmoid` 활성화 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    network = models.Sequential([\n",
    "        # 입력 형태는 (80, 80, 3) 입니다.\n",
    "        layers.Input(shape=(80, 80, 3)),\n",
    "        \n",
    "        # Convolutional Base\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Classifier Head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return network\n",
    "\n",
    "model = create_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 훈련\n",
    "전처리된 데이터를 사용하여 CNN 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 평가 및 결과 시각화\n",
    "훈련된 CNN 모델의 최종 성능을 평가하고, 훈련 과정을 시각화하여 학습 상태를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 최종 모델 평가 ---\")\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"훈련셋   => 손실값: {train_loss:.4f}, 정확도: {train_acc:.4f}\")\n",
    "print(f\"테스트셋 => 손실값: {test_loss:.4f}, 정확도: {test_acc:.4f}\")\n",
    "\n",
    "# 훈련 과정 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}